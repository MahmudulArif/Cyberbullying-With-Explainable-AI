{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10268964,
          "sourceType": "datasetVersion",
          "datasetId": 6353377
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Cyber-bullying",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "VI4W9VXyBVNJ"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "arifkaggle979_cyberbullying_path = kagglehub.dataset_download('arifkaggle979/cyberbullying')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "LpUoo2GSBVNL"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "URabz9W1BVNM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "-ozXccJyBVNM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "Dx5YTdAPBVNM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN+LSTM"
      ],
      "metadata": {
        "id": "iPT1ogRKBVNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, LSTM, Dense, Dropout, GlobalAveragePooling1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load and preprocess dataset (correctly reading the Excel file)\n",
        "data_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(data_path)\n",
        "\n",
        "# Display data overview\n",
        "print(data.head())\n",
        "\n",
        "# Preprocessing\n",
        "def preprocess_text(data):\n",
        "    # Removing special characters, stopwords, etc.\n",
        "    stopwords = set(\"অতএব অথচ অথবা\".split())  # Add actual stopwords list\n",
        "    data['cleaned_comment'] = data['comment'].str.replace(r'[^\\u0980-\\u09FFa-zA-Z0-9\\s]', '', regex=True)\n",
        "    data['cleaned_comment'] = data['cleaned_comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))\n",
        "    return data\n",
        "\n",
        "# Apply preprocessing\n",
        "data = preprocess_text(data)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data['cleaned_comment'])\n",
        "sequences = tokenizer.texts_to_sequences(data['cleaned_comment'])\n",
        "\n",
        "# Padding sequences\n",
        "max_length = 120  # Fixed length for all sequences\n",
        "data_padded = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Encoding labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()  # Ensure consistent casing and spacing\n",
        "data['encoded_label'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Extract labels\n",
        "labels = data['encoded_label'].values\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_padded, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Word Embedding using Word2Vec (Embedding Layer)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 16\n",
        "\n",
        "# Multiclass Classification Model\n",
        "multiclass_model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
        "    Conv1D(32, 3, activation='relu'),  # Maintains 3D output\n",
        "    LSTM(100, return_sequences=True, dropout=0.2, recurrent_dropout=0.2),  # Ensures 3D output\n",
        "    GlobalAveragePooling1D(),  # Correctly accepts 3D input\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')  # 5 categories\n",
        "])\n",
        "\n",
        "multiclass_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train Multiclass Model\n",
        "multiclass_model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate Multiclass Model\n",
        "multiclass_preds = np.argmax(multiclass_model.predict(X_test), axis=1)\n",
        "print(\"Multiclass Classification Report:\")\n",
        "print(classification_report(y_test, multiclass_preds, target_names=label_mapping.keys()))\n",
        "\n",
        "# Save Model\n",
        "multiclass_model.save('multiclass_bully_detection_model.h5')\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "y3jc7k4SBVNN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN+BanglaBERT"
      ],
      "metadata": {
        "id": "5tssxecdBVNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define GAN-based synthetic data generation\n",
        "class GANGenerator(torch.nn.Module):\n",
        "    def __init__(self, noise_dim, output_dim):\n",
        "        super(GANGenerator, self).__init__()\n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(noise_dim, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, output_dim),\n",
        "            torch.nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.fc(noise)\n",
        "\n",
        "def generate_synthetic_data(train_data, label_mapping, num_samples=500):\n",
        "    noise_dim = 100\n",
        "    text_length = 50\n",
        "    generator = GANGenerator(noise_dim, text_length).train()\n",
        "\n",
        "    synthetic_data = []\n",
        "    for label, encoded_label in label_mapping.items():\n",
        "        for _ in range(num_samples):\n",
        "            noise = torch.randn(1, noise_dim)\n",
        "            fake_text = generator(noise).detach().numpy()\n",
        "            text = ''.join([chr(int(abs(char)) % 1114111) for char in fake_text[0]])\n",
        "            text = ''.join([char if char.isprintable() else ' ' for char in text])  # Clean non-printable chars\n",
        "            synthetic_data.append({'comment': text, 'label': label, 'label_encoded': encoded_label})\n",
        "    return pd.DataFrame(synthetic_data)\n",
        "\n",
        "synthetic_data = generate_synthetic_data(train_data, label_mapping)\n",
        "train_data = pd.concat([train_data, synthetic_data], ignore_index=True)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Logging function for loss and accuracy\n",
        "def log_epoch_performance(epoch, train_loss, train_acc, valid_loss, valid_acc):\n",
        "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\\n\")\n",
        "\n",
        "# Training function\n",
        "def train(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    return train_loss / len(dataloader), correct / total\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    valid_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return valid_loss / len(dataloader), correct / total\n",
        "\n",
        "# Setup model, tokenizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"sagorsarker/bangla-bert-base\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_dataloader, criterion)\n",
        "    log_epoch_performance(epoch, train_loss, train_acc, valid_loss, valid_acc)\n",
        "\n",
        "# Evaluate the model and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "OW_MUJcqBVNP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "xsdPwxEiBVNQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "TNM8mhIABVNQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Data cleaning\n",
        "import re\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\u0980-\\u09FFa-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Logging function for loss and accuracy\n",
        "def log_epoch_performance(epoch, train_loss, train_acc, valid_loss, valid_acc):\n",
        "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\\n\")\n",
        "\n",
        "# Training function\n",
        "def train(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    return train_loss / len(dataloader), correct / total\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    valid_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return valid_loss / len(dataloader), correct / total\n",
        "\n",
        "# Setup model, tokenizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"sagorsarker/bangla-bert-base\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # Reduced batch size for better generalization\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)  # Lower learning rate\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "epochs = 5  # Increased epochs for better convergence\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_dataloader, criterion)\n",
        "    log_epoch_performance(epoch, train_loss, train_acc, valid_loss, valid_acc)\n",
        "\n",
        "# Evaluate the model and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "mYw4Oc68BVNQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "V35ylaZsBVNQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Advanced Data Cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^ঀ-৿a-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define GAN-based synthetic data generation\n",
        "class GANGenerator(torch.nn.Module):\n",
        "    def __init__(self, noise_dim, output_dim):\n",
        "        super(GANGenerator, self).__init__()\n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(noise_dim, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, output_dim),\n",
        "            torch.nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.fc(noise)\n",
        "\n",
        "def generate_synthetic_data(train_data, label_mapping, num_samples=500):\n",
        "    noise_dim = 100\n",
        "    text_length = 50\n",
        "    generator = GANGenerator(noise_dim, text_length).train()\n",
        "\n",
        "    synthetic_data = []\n",
        "    for label, encoded_label in label_mapping.items():\n",
        "        for _ in range(num_samples):\n",
        "            noise = torch.randn(1, noise_dim)\n",
        "            fake_text = generator(noise).detach().numpy()\n",
        "            text = ''.join([chr(int(abs(char)) % 1114111) for char in fake_text[0]])\n",
        "            text = ''.join([char if char.isprintable() else ' ' for char in text])  # Clean non-printable chars\n",
        "            synthetic_data.append({'comment': text, 'label': label, 'label_encoded': encoded_label})\n",
        "    return pd.DataFrame(synthetic_data)\n",
        "\n",
        "synthetic_data = generate_synthetic_data(train_data, label_mapping)\n",
        "train_data = pd.concat([train_data, synthetic_data], ignore_index=True)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Logging function for loss and accuracy\n",
        "def log_epoch_performance(epoch, train_loss, train_acc, valid_loss, valid_acc):\n",
        "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\\n\")\n",
        "\n",
        "# Training function\n",
        "def train(model, dataloader, optimizer, scheduler, criterion):\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    return train_loss / len(dataloader), correct / total\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    valid_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return valid_loss / len(dataloader), correct / total\n",
        "\n",
        "# Setup model, tokenizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"sagorsarker/bangla-bert-base\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Define optimizer, scheduler, and loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6)\n",
        "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, scheduler, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_dataloader, criterion)\n",
        "    log_epoch_performance(epoch, train_loss, train_acc, valid_loss, valid_acc)\n",
        "\n",
        "# Evaluate the model and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "hUXwxUZEBVNR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN+XLM-ROBERTA"
      ],
      "metadata": {
        "id": "5zhhEpWABVNR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Advanced Data Cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^ঀ-৿a-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define GAN-based synthetic data generation\n",
        "class GANGenerator(torch.nn.Module):\n",
        "    def __init__(self, noise_dim, output_dim):\n",
        "        super(GANGenerator, self).__init__()\n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(noise_dim, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, output_dim),\n",
        "            torch.nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.fc(noise)\n",
        "\n",
        "def generate_synthetic_data(train_data, label_mapping, num_samples=500):\n",
        "    noise_dim = 100\n",
        "    text_length = 50\n",
        "    generator = GANGenerator(noise_dim, text_length).train()\n",
        "\n",
        "    synthetic_data = []\n",
        "    for label, encoded_label in label_mapping.items():\n",
        "        for _ in range(num_samples):\n",
        "            noise = torch.randn(1, noise_dim)\n",
        "            fake_text = generator(noise).detach().numpy()\n",
        "            text = ''.join([chr(int(abs(char)) % 1114111) for char in fake_text[0]])\n",
        "            text = ''.join([char if char.isprintable() else ' ' for char in text])  # Clean non-printable chars\n",
        "            synthetic_data.append({'comment': text, 'label': label, 'label_encoded': encoded_label})\n",
        "    return pd.DataFrame(synthetic_data)\n",
        "\n",
        "synthetic_data = generate_synthetic_data(train_data, label_mapping)\n",
        "train_data = pd.concat([train_data, synthetic_data], ignore_index=True)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Logging function for loss and accuracy\n",
        "def log_epoch_performance(epoch, train_loss, train_acc, valid_loss, valid_acc):\n",
        "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\\n\")\n",
        "\n",
        "# Training function\n",
        "def train(model, dataloader, optimizer, scheduler, criterion):\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    return train_loss / len(dataloader), correct / total\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    valid_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return valid_loss / len(dataloader), correct / total\n",
        "\n",
        "# Setup model, tokenizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Define optimizer, scheduler, and loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6)\n",
        "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, scheduler, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_dataloader, criterion)\n",
        "    log_epoch_performance(epoch, train_loss, train_acc, valid_loss, valid_acc)\n",
        "\n",
        "# Evaluate the model and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-29T19:36:06.597463Z",
          "iopub.execute_input": "2025-01-29T19:36:06.597754Z",
          "iopub.status.idle": "2025-01-29T19:57:10.019065Z",
          "shell.execute_reply.started": "2025-01-29T19:36:06.597733Z",
          "shell.execute_reply": "2025-01-29T19:57:10.017961Z"
        },
        "id": "4UngTkQzBVNR",
        "outputId": "59b1cc5f-a4fc-427f-dcc2-2ff91585e001",
        "colab": {
          "referenced_widgets": [
            "0b0c2aef469346f0a4c7062e796c8f9c"
          ]
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:  34%|###3      | 377M/1.12G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b0c2aef469346f0a4c7062e796c8f9c"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 1/3\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training: 100%|██████████| 1917/1917 [14:03<00:00,  2.27it/s]\nEvaluation: 100%|██████████| 440/440 [00:58<00:00,  7.58it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 1 Summary:\nTrain Loss: 1.3769, Train Accuracy: 0.4112, Validation Loss: 1.0117, Validation Accuracy: 0.6280\n\n\nEpoch 2/3\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training:  41%|████      | 786/1917 [05:50<08:24,  2.24it/s]\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-22489cd3182c>\u001b[0m in \u001b[0;36m<cell line: 160>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nEpoch {epoch + 1}/{epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mlog_epoch_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-22489cd3182c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, scheduler, criterion)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "2A0YLQ7GBVNS"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "import gc\n",
        "from torch.amp import GradScaler, autocast\n",
        "\n",
        "\n",
        "# Clear GPU memory\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'\n",
        "data = pd.read_excel(file_path).dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^ঀ-৿a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define GAN-based synthetic data generation\n",
        "class GANGenerator(torch.nn.Module):\n",
        "    def __init__(self, noise_dim, output_dim):\n",
        "        super(GANGenerator, self).__init__()\n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(noise_dim, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, output_dim),\n",
        "            torch.nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.fc(noise)\n",
        "\n",
        "def generate_synthetic_data(train_data, label_mapping, num_samples=500):\n",
        "    noise_dim = 100\n",
        "    text_length = 50\n",
        "    generator = GANGenerator(noise_dim, text_length).train()\n",
        "    synthetic_data = []\n",
        "    for label, encoded_label in label_mapping.items():\n",
        "        for _ in range(num_samples):\n",
        "            noise = torch.randn(1, noise_dim)\n",
        "            fake_text = generator(noise).detach().numpy()\n",
        "            text = ''.join([chr(int(abs(char)) % 1114111) for char in fake_text[0]])\n",
        "            text = ''.join([char if char.isprintable() else ' ' for char in text])  # Clean non-printable chars\n",
        "            synthetic_data.append({'comment': text, 'label': label, 'label_encoded': encoded_label})\n",
        "    return pd.DataFrame(synthetic_data)\n",
        "\n",
        "synthetic_data = generate_synthetic_data(train_data, label_mapping)\n",
        "train_data = pd.concat([train_data, synthetic_data], ignore_index=True)\n",
        "\n",
        "# Define dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Define Focal Loss\n",
        "class FocalLoss(torch.nn.Module):\n",
        "    def __init__(self, alpha=1, gamma=2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        ce_loss = F.cross_entropy(logits, targets, reduction='none')\n",
        "        p_t = torch.exp(-ce_loss)\n",
        "        focal_loss = self.alpha * (1 - p_t) ** self.gamma * ce_loss\n",
        "        return focal_loss.mean()\n",
        "\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "accumulation_steps = 4  # Accumulate gradients over 4 steps\n",
        "\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "    # Forward pass\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    loss = criterion(outputs.logits, labels)\n",
        "\n",
        "    # Normalize the loss to account for the accumulation steps\n",
        "    loss = loss / accumulation_steps\n",
        "\n",
        "    # Backward pass\n",
        "    scaler.scale(loss).backward()\n",
        "\n",
        "    # Update weights after several steps\n",
        "    if (step + 1) % accumulation_steps == 0:\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "# Upgrade model to xlm-roberta-large with gradient checkpointing\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-large\", num_labels=len(label_mapping)).to(device)\n",
        "model.gradient_checkpointing_enable()\n",
        "\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "\n",
        "# Optimizer and scheduler adjustments\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=1e-2)\n",
        "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=500, num_training_steps=len(train_dataloader) * 10)\n",
        "criterion = FocalLoss()\n",
        "scaler = GradScaler()\n",
        "\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Training loop with progress bar\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "    # Training progress bar\n",
        "    model.train()  # Set model to training mode\n",
        "    train_loss, train_acc = 0, 0\n",
        "    correct, total = 0, 0\n",
        "    # Wrap the training dataloader with tqdm for progress bar\n",
        "    for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training\", leave=False)):\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "\n",
        "        # Normalize the loss to account for the accumulation steps\n",
        "        loss = loss / accumulation_steps\n",
        "\n",
        "        # Backward pass\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # Update weights after several steps\n",
        "        if (step + 1) % accumulation_steps == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        # For accuracy tracking\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # Update loss and accuracy\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Calculate average loss and accuracy for training\n",
        "    train_loss /= len(train_dataloader)\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # Validation progress bar\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    valid_loss, valid_acc = evaluate(model, val_dataloader, criterion)\n",
        "\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.4f}\")\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_model(model, test_dataloader):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids, attention_mask, labels = batch['input_ids'].to(device), batch['attention_mask'].to(device), batch['labels'].to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues')\n",
        "    plt.show()\n",
        "\n",
        "evaluate_model(model, test_dataloader)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-29T20:26:08.480179Z",
          "iopub.execute_input": "2025-01-29T20:26:08.480509Z"
        },
        "id": "tN3tTKceBVNS",
        "outputId": "b2c9930b-d2dd-4349-d9c4-a5c8310fceff"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BanglishBERT"
      ],
      "metadata": {
        "id": "z6Q8Py3MBVNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Data cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\u0980-\\u09FFa-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Setup model, tokenizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglishbert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"csebuetnlp/banglishbert\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Define optimizer, loss function, and learning rate scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop with formatted output\n",
        "epochs = 5\n",
        "learning_rate = 2e-5\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            \"accuracy\": f\"{(correct / total):.4f}\",\n",
        "            \"loss\": f\"{(train_loss / (total / train_dataloader.batch_size)):.4f}\",\n",
        "        })\n",
        "\n",
        "    train_accuracy = correct / total\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    val_loss /= len(val_dataloader)\n",
        "\n",
        "    # Fetch current learning rate\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    # Print epoch summary\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} ━ {epoch_time:.1f}s - accuracy: {train_accuracy:.4f} - loss: {train_loss:.4f} - val_accuracy: {val_accuracy:.4f} - val_loss: {val_loss:.4f} - learning_rate: {current_lr:.6f}\")\n",
        "\n",
        "# Evaluate the model and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:56:12.340546Z",
          "iopub.execute_input": "2025-01-30T09:56:12.340905Z",
          "iopub.status.idle": "2025-01-30T10:53:47.135108Z",
          "shell.execute_reply.started": "2025-01-30T09:56:12.340876Z",
          "shell.execute_reply": "2025-01-30T10:53:47.134224Z"
        },
        "id": "PubT7aEHBVNT",
        "outputId": "80d14c85-c428-4b80-b9a7-50e576ed5cd5"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "`clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglishbert and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEpoch 1/5: 100%|██████████| 880/880 [10:20<00:00,  1.42it/s, accuracy=0.7380, loss=0.7201]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1/5 ━ 676.2s - accuracy: 0.7380 - loss: 0.7201 - val_accuracy: 0.8139 - val_loss: 0.5756 - learning_rate: 0.000020\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 2/5: 100%|██████████| 880/880 [10:19<00:00,  1.42it/s, accuracy=0.8454, loss=0.4631]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2/5 ━ 676.0s - accuracy: 0.8454 - loss: 0.4631 - val_accuracy: 0.8250 - val_loss: 0.5261 - learning_rate: 0.000020\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 3/5: 100%|██████████| 880/880 [10:20<00:00,  1.42it/s, accuracy=0.8843, loss=0.3543]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3/5 ━ 676.2s - accuracy: 0.8843 - loss: 0.3543 - val_accuracy: 0.8169 - val_loss: 0.5672 - learning_rate: 0.000020\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 4/5: 100%|██████████| 880/880 [10:19<00:00,  1.42it/s, accuracy=0.9198, loss=0.2490]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4/5 ━ 675.7s - accuracy: 0.9198 - loss: 0.2490 - val_accuracy: 0.8249 - val_loss: 0.6474 - learning_rate: 0.000020\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 5/5: 100%|██████████| 880/880 [10:19<00:00,  1.42it/s, accuracy=0.9458, loss=0.1731]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5/5 ━ 675.4s - accuracy: 0.9458 - loss: 0.1731 - val_accuracy: 0.8195 - val_loss: 0.6937 - learning_rate: 0.000020\n\nClassification Report:\n\n              precision    recall  f1-score   support\n\n   not bully       0.86      0.84      0.85      3068\n      sexual       0.86      0.78      0.82      1786\n      threat       0.76      0.71      0.73       339\n       troll       0.71      0.79      0.75      2093\n   religious       0.89      0.92      0.90      1515\n\n    accuracy                           0.82      8801\n   macro avg       0.82      0.81      0.81      8801\nweighted avg       0.83      0.82      0.82      8801\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 800x600 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import RandomOverSampler  # For random oversampling\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import time\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Data cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\u0980-\\u09FFa-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Random oversample using RandomOverSampler for the entire dataset\n",
        "def random_oversample_data(data):\n",
        "    X = data['comment'].values\n",
        "    y = data['label_encoded'].values\n",
        "\n",
        "    # Apply RandomOverSampler to oversample the dataset\n",
        "    ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
        "    X_resampled, y_resampled = ros.fit_resample(X.reshape(-1, 1), y)\n",
        "\n",
        "    # Create a new DataFrame with the oversampled data\n",
        "    data_resampled = pd.DataFrame({\n",
        "        'comment': X_resampled.flatten(),\n",
        "        'label_encoded': y_resampled\n",
        "    })\n",
        "\n",
        "    return data_resampled\n",
        "\n",
        "# Oversample the entire dataset (train, validation, and test)\n",
        "data_resampled = random_oversample_data(data)\n",
        "\n",
        "# Split dataset into train, validation, and test (using a basic 80-10-10 split)\n",
        "train_data = data_resampled.sample(frac=0.8, random_state=42)\n",
        "test_val_data = data_resampled.drop(train_data.index)\n",
        "val_data = test_val_data.sample(frac=0.5, random_state=42)\n",
        "test_data = test_val_data.drop(val_data.index)\n",
        "\n",
        "# Dataloaders\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglishbert\")\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Setup the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"csebuetnlp/banglishbert\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "# Training settings\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)  # Lower learning rate for fine-tuning\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train model with BERT (fine-tuning for 5 epochs)\n",
        "model.train()\n",
        "for epoch in range(5):  # 5 epochs\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\", ncols=100)\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Update the progress bar with training loss and accuracy\n",
        "        progress_bar.set_postfix({\n",
        "            'Loss': f'{train_loss / (total / train_dataloader.batch_size):.4f}',\n",
        "            'Accuracy': f'{(correct / total):.4f}'\n",
        "        })\n",
        "\n",
        "    # After each epoch, print out the final accuracy and loss\n",
        "    train_accuracy = correct / total\n",
        "    print(f\"Epoch {epoch + 1} - Accuracy: {train_accuracy:.4f} - Loss: {train_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "true_labels, pred_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\\n\")\n",
        "print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T16:36:47.121627Z",
          "iopub.execute_input": "2025-01-30T16:36:47.121912Z",
          "iopub.status.idle": "2025-01-30T18:20:51.38313Z",
          "shell.execute_reply.started": "2025-01-30T16:36:47.12189Z",
          "shell.execute_reply": "2025-01-30T18:20:51.382112Z"
        },
        "id": "SOb4SRGsBVNT",
        "outputId": "3b537b59-b7a5-40bf-944e-70e58a638a10"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglishbert and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEpoch 1: 100%|██████████████████████| 959/959 [20:36<00:00,  1.29s/it, Loss=0.6014, Accuracy=0.7830]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Accuracy: 0.7830 - Loss: 0.6013\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 2: 100%|██████████████████████| 959/959 [20:35<00:00,  1.29s/it, Loss=0.3178, Accuracy=0.8957]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Accuracy: 0.8957 - Loss: 0.3177\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 3: 100%|██████████████████████| 959/959 [20:35<00:00,  1.29s/it, Loss=0.2141, Accuracy=0.9310]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Accuracy: 0.9310 - Loss: 0.2141\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 4: 100%|██████████████████████| 959/959 [20:35<00:00,  1.29s/it, Loss=0.1465, Accuracy=0.9547]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Accuracy: 0.9547 - Loss: 0.1464\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 5: 100%|██████████████████████| 959/959 [20:36<00:00,  1.29s/it, Loss=0.1014, Accuracy=0.9681]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Accuracy: 0.9681 - Loss: 0.1014\n\nClassification Report (Test Set):\n\n              precision    recall  f1-score   support\n\n   not bully       0.92      0.81      0.86      1525\n      sexual       0.91      0.94      0.92      1526\n      threat       0.97      0.99      0.98      1512\n       troll       0.83      0.90      0.86      1551\n   religious       0.97      0.96      0.97      1556\n\n    accuracy                           0.92      7670\n   macro avg       0.92      0.92      0.92      7670\nweighted avg       0.92      0.92      0.92      7670\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 800x600 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "VWV4FiM4BVNU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "CQbfRoPUBVNU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Data cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\u0980-\\u09FFa-zA-Z0-9\\s]', '', text)  # Keep only Bangla and English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset (80% train, 10% validation, 10% test)\n",
        "train_data = data.sample(frac=0.8, random_state=42)\n",
        "test_val_data = data.drop(train_data.index)\n",
        "val_data = test_val_data.sample(frac=0.5, random_state=42)\n",
        "test_data = test_val_data.drop(val_data.index)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Dataloaders\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglishbert\")\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "# Calculate class weights for the WeightedRandomSampler\n",
        "class_counts = train_data['label_encoded'].value_counts().sort_index().tolist()\n",
        "weights = [sum(class_counts) / c for c in class_counts]\n",
        "sample_weights = [weights[label] for label in train_data['label_encoded']]\n",
        "\n",
        "# Create the WeightedRandomSampler\n",
        "sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# DataLoader with Random Sampler\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, sampler=sampler)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Load the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"csebuetnlp/banglishbert\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "# Define class weights for balanced training\n",
        "class_weights = torch.tensor(weights, dtype=torch.float).to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "# Train model (10 epochs with learning rate scheduling)\n",
        "model.train()\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.8)\n",
        "\n",
        "for epoch in range(10):  # Increased epochs for higher accuracy\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\")\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        progress_bar.set_postfix({'Loss': f'{train_loss / (total / train_dataloader.batch_size):.4f}',\n",
        "                                  'Accuracy': f'{(correct / total):.4f}'})\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} - Accuracy: {correct / total:.4f} - Loss: {train_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "model.eval()\n",
        "true_labels, pred_labels = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\\n\")\n",
        "print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "# Confusion matrix visualization\n",
        "cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-02T11:49:04.211773Z",
          "iopub.execute_input": "2025-02-02T11:49:04.212089Z",
          "iopub.status.idle": "2025-02-02T13:59:49.769514Z",
          "shell.execute_reply.started": "2025-02-02T11:49:04.212062Z",
          "shell.execute_reply": "2025-02-02T13:59:49.768658Z"
        },
        "id": "pPpUbUuHBVNU",
        "outputId": "4321ef78-8ede-4ef9-dfb5-935544e3770c"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglishbert and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEpoch 1: 100%|██████████| 551/551 [13:01<00:00,  1.42s/it, Loss=0.6594, Accuracy=0.5585]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Accuracy: 0.5585 - Loss: 0.6583\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 2: 100%|██████████| 551/551 [12:59<00:00,  1.42s/it, Loss=0.3107, Accuracy=0.7919]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Accuracy: 0.7919 - Loss: 0.3101\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 3: 100%|██████████| 551/551 [13:01<00:00,  1.42s/it, Loss=0.2296, Accuracy=0.8416]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Accuracy: 0.8416 - Loss: 0.2292\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 4: 100%|██████████| 551/551 [13:00<00:00,  1.42s/it, Loss=0.2142, Accuracy=0.8537]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Accuracy: 0.8537 - Loss: 0.2139\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 5: 100%|██████████| 551/551 [13:01<00:00,  1.42s/it, Loss=0.1836, Accuracy=0.8775]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Accuracy: 0.8775 - Loss: 0.1833\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 6: 100%|██████████| 551/551 [12:59<00:00,  1.41s/it, Loss=0.1775, Accuracy=0.8835]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 6 - Accuracy: 0.8835 - Loss: 0.1772\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 7: 100%|██████████| 551/551 [12:59<00:00,  1.42s/it, Loss=0.1494, Accuracy=0.8991]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 7 - Accuracy: 0.8991 - Loss: 0.1491\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 8: 100%|██████████| 551/551 [12:59<00:00,  1.42s/it, Loss=0.1422, Accuracy=0.9044]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 8 - Accuracy: 0.9044 - Loss: 0.1419\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 9: 100%|██████████| 551/551 [12:59<00:00,  1.42s/it, Loss=0.1312, Accuracy=0.9123]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 9 - Accuracy: 0.9123 - Loss: 0.1310\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 10: 100%|██████████| 551/551 [12:59<00:00,  1.41s/it, Loss=0.1175, Accuracy=0.9211]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 10 - Accuracy: 0.9211 - Loss: 0.1173\n\nClassification Report (Test Set):\n\n              precision    recall  f1-score   support\n\n   not bully       0.94      0.68      0.79      1568\n      sexual       0.76      0.83      0.79       870\n      threat       0.68      0.84      0.75       167\n       troll       0.63      0.80      0.70      1007\n   religious       0.89      0.93      0.91       788\n\n    accuracy                           0.79      4400\n   macro avg       0.78      0.82      0.79      4400\nweighted avg       0.81      0.79      0.79      4400\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 800x600 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import time\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Data cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\u0980-\\u09FFa-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Random oversample using RandomOverSampler for the entire dataset\n",
        "def random_oversample_data(data):\n",
        "    X = data['comment'].values\n",
        "    y = data['label_encoded'].values\n",
        "\n",
        "    # Apply RandomOverSampler to oversample the dataset\n",
        "    ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
        "    X_resampled, y_resampled = ros.fit_resample(X.reshape(-1, 1), y)\n",
        "\n",
        "    # Create a new DataFrame with the oversampled data\n",
        "    data_resampled = pd.DataFrame({\n",
        "        'comment': X_resampled.flatten(),\n",
        "        'label_encoded': y_resampled\n",
        "    })\n",
        "\n",
        "    return data_resampled\n",
        "\n",
        "# Apply oversampling only to the training data\n",
        "train_data = data.sample(frac=0.8, random_state=42)\n",
        "train_data_resampled = random_oversample_data(train_data)\n",
        "\n",
        "# Split dataset into train, validation, and test\n",
        "test_val_data = data.drop(train_data.index)\n",
        "val_data = test_val_data.sample(frac=0.5, random_state=42)\n",
        "test_data = test_val_data.drop(val_data.index)\n",
        "\n",
        "# Dataloaders\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglishbert\")\n",
        "train_dataset = BanglaDataset(train_data_resampled, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Setup the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"csebuetnlp/banglishbert\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "# Calculate class weights (for imbalanced classes)\n",
        "class_weights = compute_class_weight('balanced', classes=list(label_mapping.values()), y=train_data_resampled['label_encoded'])\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# Training settings\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)  # Lower learning rate for fine-tuning\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)  # Apply class weights to the loss function\n",
        "\n",
        "# Train model with BERT (fine-tuning for 10 epochs)\n",
        "model.train()\n",
        "for epoch in range(10):  # Increase epochs to 10\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}\", ncols=100)\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Update the progress bar with training loss and accuracy\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(labels.cpu(), predicted.cpu(), average='weighted')\n",
        "        progress_bar.set_postfix({\n",
        "            'Loss': f'{train_loss / (total / train_dataloader.batch_size):.4f}',\n",
        "            'Accuracy': f'{(correct / total):.4f}',\n",
        "            'Precision': f'{precision:.4f}',\n",
        "            'Recall': f'{recall:.4f}',\n",
        "            'F1-score': f'{f1:.4f}'\n",
        "        })\n",
        "\n",
        "    # After each epoch, print out the final accuracy and loss\n",
        "    train_accuracy = correct / total\n",
        "    print(f\"Epoch {epoch + 1} - Accuracy: {train_accuracy:.4f} - Loss: {train_loss / len(train_dataloader):.4f}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "model.eval()\n",
        "true_labels, pred_labels = [], []\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        true_labels.extend(labels.cpu().numpy())\n",
        "        pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "print(\"\\nClassification Report (Test Set):\\n\")\n",
        "print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-01T10:31:35.678803Z",
          "iopub.execute_input": "2025-02-01T10:31:35.679077Z",
          "iopub.status.idle": "2025-02-01T14:16:35.275262Z",
          "shell.execute_reply.started": "2025-02-01T10:31:35.679056Z",
          "shell.execute_reply": "2025-02-01T14:16:35.274446Z"
        },
        "id": "mDi3IambBVNU",
        "outputId": "8e621510-3e1a-4928-f73c-6d13487d6817",
        "colab": {
          "referenced_widgets": [
            "5921bcd859c847329629ab0094fe1157",
            "756e08d4c29f451cbf2531ef9658fbd0",
            "599d9351aef94a659fcff6a99216c4d9",
            "1a0e72d1d5f34fe59c0c79c790a82dfc",
            "1fa9eb50926f4fab8df4eba98a68f466"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5921bcd859c847329629ab0094fe1157"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/874 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "756e08d4c29f451cbf2531ef9658fbd0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/366k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "599d9351aef94a659fcff6a99216c4d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a0e72d1d5f34fe59c0c79c790a82dfc"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fa9eb50926f4fab8df4eba98a68f466"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglishbert and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEpoch 1:   0%|                                                              | 0/961 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1:   0%| | 3/961 [00:04<22:04,  1.38s/it, Loss=1.6192, Accuracy=0.1823, Precision=0.2001, Reca/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1:   0%| | 4/961 [00:05<21:00,  1.32s/it, Loss=1.6127, Accuracy=0.1953, Precision=0.1320, Reca/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1:   1%| | 5/961 [00:06<20:28,  1.29s/it, Loss=1.6123, Accuracy=0.1906, Precision=0.0451, Reca/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1:   1%| | 6/961 [00:08<20:10,  1.27s/it, Loss=1.6104, Accuracy=0.2005, Precision=0.2013, Reca/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1:   1%| | 7/961 [00:09<20:03,  1.26s/it, Loss=1.6111, Accuracy=0.2054, Precision=0.2109, Reca/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1:   1%| | 8/961 [00:10<19:54,  1.25s/it, Loss=1.6101, Accuracy=0.2109, Precision=0.2262, Reca/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1:   1%| | 9/961 [00:11<19:52,  1.25s/it, Loss=1.6083, Accuracy=0.2222, Precision=0.1438, Reca/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1:   1%| | 10/961 [00:13<19:46,  1.25s/it, Loss=1.6066, Accuracy=0.2281, Precision=0.2204, Rec/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1:   1%| | 12/961 [00:15<19:46,  1.25s/it, Loss=1.6034, Accuracy=0.2370, Precision=0.4946, Rec/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1:   1%| | 13/961 [00:16<19:46,  1.25s/it, Loss=1.6006, Accuracy=0.2488, Precision=0.3278, Rec/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1:   1%| | 14/961 [00:18<19:49,  1.26s/it, Loss=1.6006, Accuracy=0.2467, Precision=0.2176, Rec/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1:   3%| | 26/961 [00:33<20:17,  1.30s/it, Loss=1.5796, Accuracy=0.2891, Precision=0.5057, Rec/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\nEpoch 1: 100%|█| 961/961 [22:22<00:00,  1.40s/it, Loss=0.6046, Accuracy=0.7813, Precision=0.8500, Re\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1 - Accuracy: 0.7813 - Loss: 0.6041\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 2: 100%|█| 961/961 [22:25<00:00,  1.40s/it, Loss=0.3108, Accuracy=0.8974, Precision=0.9250, Re\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2 - Accuracy: 0.8974 - Loss: 0.3105\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 3: 100%|█| 961/961 [22:25<00:00,  1.40s/it, Loss=0.2049, Accuracy=0.9360, Precision=1.0000, Re\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3 - Accuracy: 0.9360 - Loss: 0.2047\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 4: 100%|█| 961/961 [22:24<00:00,  1.40s/it, Loss=0.1394, Accuracy=0.9571, Precision=1.0000, Re\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4 - Accuracy: 0.9571 - Loss: 0.1393\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 5: 100%|█| 961/961 [22:25<00:00,  1.40s/it, Loss=0.1025, Accuracy=0.9684, Precision=1.0000, Re\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5 - Accuracy: 0.9684 - Loss: 0.1024\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 6: 100%|█| 961/961 [22:26<00:00,  1.40s/it, Loss=0.0753, Accuracy=0.9766, Precision=1.0000, Re\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 6 - Accuracy: 0.9766 - Loss: 0.0752\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 7: 100%|█| 961/961 [22:26<00:00,  1.40s/it, Loss=0.0597, Accuracy=0.9816, Precision=1.0000, Re\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 7 - Accuracy: 0.9816 - Loss: 0.0597\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 8: 100%|█| 961/961 [22:25<00:00,  1.40s/it, Loss=0.0531, Accuracy=0.9835, Precision=1.0000, Re\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 8 - Accuracy: 0.9835 - Loss: 0.0531\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 9: 100%|█| 961/961 [22:25<00:00,  1.40s/it, Loss=0.0425, Accuracy=0.9868, Precision=1.0000, Re\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 9 - Accuracy: 0.9868 - Loss: 0.0424\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Epoch 10: 100%|█| 961/961 [22:24<00:00,  1.40s/it, Loss=0.0389, Accuracy=0.9871, Precision=1.0000, R\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 10 - Accuracy: 0.9871 - Loss: 0.0389\n\nClassification Report (Test Set):\n\n              precision    recall  f1-score   support\n\n   not bully       0.88      0.85      0.87      1568\n      sexual       0.82      0.84      0.83       870\n      threat       0.79      0.82      0.81       167\n       troll       0.77      0.80      0.78      1007\n   religious       0.93      0.90      0.92       788\n\n    accuracy                           0.85      4400\n   macro avg       0.84      0.84      0.84      4400\nweighted avg       0.85      0.85      0.85      4400\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 800x600 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_cosine_schedule_with_warmup\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Enhanced data cleaning with Banglish handling\n",
        "def clean_text(text):\n",
        "    # Remove unwanted characters (URLs, special symbols, etc.)\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+|[^\\u0980-\\u09FFa-zA-Z0-9\\s]', '', text)  # Remove URLs & symbols\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "\n",
        "    # Tokenization and Banglish handling\n",
        "    # Ideally, you would want a Banglish detector here, this is a placeholder for demonstration\n",
        "    text = ' '.join([word if word.isalpha() else '' for word in text.split()])  # Remove numeric tokens\n",
        "\n",
        "    # Apply more specific cleaning and lemmatization (assuming lemmatizer is available, like spaCy for Bangla)\n",
        "    # Here we can apply basic stemming or lemmatization as needed\n",
        "\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=seed)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=seed)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Setup model, tokenizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglishbert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"csebuetnlp/banglishbert\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Apply SMOTE to balance the dataset\n",
        "X_train = [item['comment'] for item in train_dataset]\n",
        "y_train = [item['labels'] for item in train_dataset]\n",
        "\n",
        "# Convert text to numerical format (e.g., TF-IDF Vectorization)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=seed)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "# Recreate the DataLoader for the oversampled data\n",
        "train_dataset_resampled = BanglaDataset(data=pd.DataFrame({\"comment\": X_train_res, \"label_encoded\": y_train_res}), tokenizer=tokenizer, max_length=128)\n",
        "train_dataloader_resampled = DataLoader(train_dataset_resampled, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define optimizer, loss function, and learning rate scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Learning rate scheduler with warm-up and cosine annealing\n",
        "total_steps = len(train_dataloader_resampled) * 5  # Total number of training steps\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training loop with gradient clipping and early stopping\n",
        "epochs = 8\n",
        "best_val_accuracy = 0\n",
        "patience = 2  # Number of epochs with no improvement before stopping\n",
        "early_stopping_counter = 0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    progress_bar = tqdm(train_dataloader_resampled, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping to avoid exploding gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            \"accuracy\": f\"{(correct / total):.4f}\",\n",
        "            \"loss\": f\"{(train_loss / (total / train_dataloader_resampled.batch_size)):.4f}\",\n",
        "        })\n",
        "\n",
        "    train_accuracy = correct / total\n",
        "    train_loss /= len(train_dataloader_resampled)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    val_loss /= len(val_dataloader)\n",
        "\n",
        "    # Print epoch summary\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} ━ {epoch_time:.1f}s - accuracy: {train_accuracy:.4f} - loss: {train_loss:.4f} - val_accuracy: {val_accuracy:.4f} - val_loss: {val_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T16:21:50.44966Z",
          "iopub.execute_input": "2025-01-30T16:21:50.449855Z",
          "iopub.status.idle": "2025-01-30T16:22:10.378023Z",
          "shell.execute_reply.started": "2025-01-30T16:21:50.449836Z",
          "shell.execute_reply": "2025-01-30T16:22:10.376775Z"
        },
        "id": "v3QIDOSdBVNV",
        "outputId": "2722bb61-e187-4f5f-9401-8b229a2565c9",
        "colab": {
          "referenced_widgets": [
            "35a9abb3da044321aaf7ae04cfb9f436",
            "22a4482a4b2e4f98a2ee41d913d42d42",
            "5db8c55cb82149318a06071e30bbf902",
            "94082d19e5db4af3a2a56d5f79970e36",
            "0106470bdb9e4d4183d22cc44ea345fe"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35a9abb3da044321aaf7ae04cfb9f436"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/874 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22a4482a4b2e4f98a2ee41d913d42d42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/366k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5db8c55cb82149318a06071e30bbf902"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94082d19e5db4af3a2a56d5f79970e36"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0106470bdb9e4d4183d22cc44ea345fe"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglishbert and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cd2a42f89627>\u001b[0m in \u001b[0;36m<cell line: 95>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# Apply SMOTE to balance the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-cd2a42f89627>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;31m# Apply SMOTE to balance the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'comment'"
          ],
          "ename": "KeyError",
          "evalue": "'comment'",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install git+https://github.com/csebuetnlp/normalizer\n",
        "!pip install transformers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Data cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\u0980-\\u09FFa-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Oversample minority classes using SMOTE (on TF-IDF vectors)\n",
        "X_train, y_train = train_data['comment'], train_data['label_encoded']\n",
        "\n",
        "# Convert text to TF-IDF vectors\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Apply SMOTE to oversample\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X_train_tfidf, y_train)\n",
        "\n",
        "# Shuffle the resampled dataset\n",
        "X_res, y_res = shuffle(X_res, y_res, random_state=42)\n",
        "\n",
        "# Convert oversampled data back to a DataFrame for further processing\n",
        "train_data_resampled = pd.DataFrame(X_res.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
        "train_data_resampled['label_encoded'] = y_res\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "\n",
        "        # Ensure that the text is a valid string\n",
        "        if not isinstance(text, str):\n",
        "            text = str(text)  # Convert to string if it's not\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "\n",
        "# Setup model, tokenizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglishbert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"csebuetnlp/banglishbert\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "# Use oversampled data for training\n",
        "train_dataset = BanglaDataset(train_data_resampled, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Define optimizer, loss function with class weights, and learning rate scheduler\n",
        "class_weights = torch.tensor([1.0, 2.0, 3.0, 1.5, 2.5]).to(device)  # Example class weights; adjust based on your data\n",
        "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "epochs = 5\n",
        "\n",
        "# Training loop with formatted output\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            \"accuracy\": f\"{(correct / total):.4f}\",\n",
        "            \"loss\": f\"{(train_loss / (total / train_dataloader.batch_size)):.4f}\",\n",
        "        })\n",
        "\n",
        "    train_accuracy = correct / total\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    val_loss /= len(val_dataloader)\n",
        "\n",
        "    # Fetch current learning rate\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    # Print epoch summary\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} ━ {epoch_time:.1f}s - accuracy: {train_accuracy:.4f} - loss: {train_loss:.4f} - val_accuracy: {val_accuracy:.4f} - val_loss: {val_loss:.4f} - learning_rate: {current_lr:.6f}\")\n",
        "\n",
        "# Evaluate the model and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:53:54.554077Z",
          "iopub.execute_input": "2025-01-30T09:53:54.554432Z",
          "iopub.status.idle": "2025-01-30T09:56:09.230544Z",
          "shell.execute_reply.started": "2025-01-30T09:53:54.554404Z",
          "shell.execute_reply": "2025-01-30T09:56:09.229212Z"
        },
        "id": "atjf9XbvBVNV",
        "outputId": "9aa66202-4f8e-4255-f311-3138cfbb4c59"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting git+https://github.com/csebuetnlp/normalizer\n  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-_k6a8yjm\n  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer /tmp/pip-req-build-_k6a8yjm\n  Resolved https://github.com/csebuetnlp/normalizer to commit d405944dde5ceeacb7c2fd3245ae2a9dea5f35c9\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from normalizer==0.0.1) (2024.9.11)\nRequirement already satisfied: emoji==1.4.2 in /usr/local/lib/python3.10/dist-packages (from normalizer==0.0.1) (1.4.2)\nRequirement already satisfied: ftfy==6.0.3 in /usr/local/lib/python3.10/dist-packages (from normalizer==0.0.1) (6.0.3)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.2.13)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "`clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglishbert and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEpoch 1/5:  10%|█         | 161/1535 [01:53<16:06,  1.42it/s, accuracy=0.1908, loss=1.5592]\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-59e098128a58>\u001b[0m in \u001b[0;36m<cell line: 117>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         progress_bar.set_postfix({\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explainable AI"
      ],
      "metadata": {
        "id": "FhvuempLBVNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UV-O8VT-BVNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shap\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Data cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^ঀ-৿a-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Setup model, tokenizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-large\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Define optimizer, loss function, and learning rate scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop with formatted output\n",
        "epochs = 5\n",
        "learning_rate = 2e-5\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            \"accuracy\": f\"{(correct / total):.4f}\",\n",
        "            \"loss\": f\"{(train_loss / (total / train_dataloader.batch_size)):.4f}\",\n",
        "        })\n",
        "\n",
        "    train_accuracy = correct / total\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    val_loss /= len(val_dataloader)\n",
        "\n",
        "    # Fetch current learning rate\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    # Print epoch summary\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} ━ {epoch_time:.1f}s - accuracy: {train_accuracy:.4f} - loss: {train_loss:.4f} - val_accuracy: {val_accuracy:.4f} - val_loss: {val_loss:.4f} - learning_rate: {current_lr:.6f}\")\n",
        "\n",
        "# Evaluate the model and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n",
        "\n",
        "# Explainability using SHAP\n",
        "def explain_with_shap(model, tokenizer, texts, max_length):\n",
        "    explainer = shap.Explainer(lambda x: model(\n",
        "        tokenizer(x, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(device))\n",
        "        .logits.detach().cpu().numpy(),\n",
        "        texts\n",
        "    )\n",
        "    shap_values = explainer(texts)\n",
        "    shap.summary_plot(shap_values, texts)\n",
        "\n",
        "# Example usage of SHAP\n",
        "sample_texts = [\"আপনার ধর্ম নিয়ে আপত্তিকর মন্তব্য করা ঠিক নয়।\", \"তোমাকে জুতা পেটা করা উচিত।\"]\n",
        "explain_with_shap(model, tokenizer, sample_texts, max_length=128)\n",
        "\n",
        "# Explainability using LIME\n",
        "lime_explainer = LimeTextExplainer(class_names=list(label_mapping.keys()))\n",
        "def explain_with_lime(text, model, tokenizer, max_length):\n",
        "    def predict_proba(texts):\n",
        "        inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length).to(device)\n",
        "        outputs = model(**inputs).logits.detach().cpu().numpy()\n",
        "        return outputs\n",
        "\n",
        "    explanation = lime_explainer.explain_instance(text, predict_proba, num_features=10)\n",
        "    explanation.show_in_notebook()\n",
        "\n",
        "# Example usage of LIME\n",
        "example_text = \"তোমাকে জুতা পেটা করা উচিত।\"\n",
        "explain_with_lime(example_text, model, tokenizer, max_length=128)"
      ],
      "metadata": {
        "trusted": true,
        "id": "RuQ1hsgGBVNW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shap\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Data cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\u0980-\\u09FFa-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "\n",
        "# Setup model, tokenizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"xlm-roberta-large\", num_labels=len(label_mapping)\n",
        ").to(device)\n",
        "\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8)\n",
        "\n",
        "# Define optimizer, loss function, and learning rate scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "epochs = 1\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            \"accuracy\": f\"{(correct / total):.4f}\",\n",
        "            \"loss\": f\"{(train_loss / (total / train_dataloader.batch_size)):.4f}\",\n",
        "        })\n",
        "\n",
        "    train_accuracy = correct / total\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    val_loss /= len(val_dataloader)\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} ━ {epoch_time:.1f}s - accuracy: {train_accuracy:.4f} - loss: {train_loss:.4f} - val_accuracy: {val_accuracy:.4f} - val_loss: {val_loss:.4f}\")\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "gy5OcSMIBVNW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np  # Import numpy for handling arrays\n",
        "\n",
        "def explain_with_shap_bar_plot(model, tokenizer, texts, max_length):\n",
        "    # Define a model wrapper for SHAP\n",
        "    def model_wrapper(input_texts):\n",
        "        if isinstance(input_texts, np.ndarray):  # Convert SHAP's masked inputs back to text\n",
        "            input_texts = [\"\".join([t for t in text if t != \"[MASK]\"]) for text in input_texts]\n",
        "\n",
        "        encoding = tokenizer(\n",
        "            input_texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        input_ids = encoding['input_ids'].to(device)\n",
        "        attention_mask = encoding['attention_mask'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask).logits\n",
        "        return outputs.cpu().detach().numpy()\n",
        "\n",
        "    # Initialize SHAP Explainer\n",
        "    masker = shap.maskers.Text(tokenizer)  # Create a text masker\n",
        "    explainer = shap.Explainer(model_wrapper, masker)\n",
        "\n",
        "    # Explain the provided texts\n",
        "    shap_values = explainer(texts, max_evals=500, batch_size=16)\n",
        "\n",
        "    # Generate a SHAP bar plot\n",
        "    shap.summary_plot(shap_values.values, shap_values.feature_names, plot_type=\"bar\")\n",
        "\n",
        "# Example usage of the corrected function\n",
        "sample_texts = [\"তোমাকে জুতা পেটা করা উচিত।\"]\n",
        "explain_with_shap_bar_plot(model, tokenizer, sample_texts, max_length=128)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-07T17:16:24.636579Z",
          "iopub.execute_input": "2025-01-07T17:16:24.637197Z",
          "iopub.status.idle": "2025-01-07T17:16:30.934732Z",
          "shell.execute_reply.started": "2025-01-07T17:16:24.637168Z",
          "shell.execute_reply": "2025-01-07T17:16:30.933508Z"
        },
        "id": "6JN3O4KrBVNX",
        "outputId": "853389cb-0c7c-4c9a-a25c-c6ccd6c4f559"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bebfc54e9829>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Example usage of the corrected function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0msample_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"তোমাকে জুতা পেটা করা উচিত।\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mexplain_with_shap_bar_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ],
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np  # Import numpy for handling arrays\n",
        "\n",
        "def explain_with_shap(model, tokenizer, texts, max_length):\n",
        "    # Define a model wrapper for SHAP\n",
        "    def model_wrapper(input_texts):\n",
        "        if isinstance(input_texts, np.ndarray):  # Convert SHAP's masked inputs back to text\n",
        "            input_texts = [\"\".join([t for t in text if t != \"[MASK]\"]) for text in input_texts]\n",
        "\n",
        "        encoding = tokenizer(\n",
        "            input_texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        input_ids = encoding['input_ids'].to(device)\n",
        "        attention_mask = encoding['attention_mask'].to(device)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask).logits\n",
        "        return outputs.cpu().detach().numpy()\n",
        "\n",
        "    # Initialize SHAP Explainer\n",
        "    masker = shap.maskers.Text(tokenizer)  # Create a text masker\n",
        "    explainer = shap.Explainer(model_wrapper, masker)\n",
        "\n",
        "    # Explain the provided texts\n",
        "    shap_values = explainer(texts, max_evals=500, batch_size=16)\n",
        "\n",
        "    # Visualize the results\n",
        "    shap.text_plot(shap_values)\n",
        "\n",
        "# Example usage of the corrected function\n",
        "sample_texts =\"তোমাকে জুতা পেটা করা উচিত।\"\n",
        "explain_with_shap(model, tokenizer, sample_texts, max_length=128)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-07T17:16:48.199987Z",
          "iopub.execute_input": "2025-01-07T17:16:48.200306Z",
          "iopub.status.idle": "2025-01-07T17:16:48.21591Z",
          "shell.execute_reply.started": "2025-01-07T17:16:48.200279Z",
          "shell.execute_reply": "2025-01-07T17:16:48.21485Z"
        },
        "id": "lL9yc25_BVNX",
        "outputId": "16a62052-103b-4eb2-84f9-d2ec7b947ce6"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9b3b1b08678a>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Example usage of the corrected function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0msample_texts\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"তোমাকে জুতা পেটা করা উচিত।\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mexplain_with_shap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ],
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime\n",
        "\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "# Define a predict function for LIME\n",
        "def lime_predict(texts):\n",
        "    encoding = tokenizer(\n",
        "        texts,\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    # Get model predictions\n",
        "    outputs = model(input_ids, attention_mask=attention_mask).logits\n",
        "    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "    return probabilities.detach().cpu().numpy()\n",
        "\n",
        "# Initialize LIME Explainer\n",
        "explainer = LimeTextExplainer(class_names=list(label_mapping.keys()))\n",
        "\n",
        "# Example text to explain\n",
        "example_text = \"তোমাকে জুতা পেটা করা উচিত\"\n",
        "\n",
        "# Generate LIME explanation\n",
        "exp = explainer.explain_instance(\n",
        "    example_text,\n",
        "    lime_predict,  # Pass the prediction function\n",
        "    num_features=10,  # Number of words to explain in the visualization\n",
        "    labels=[0, 1, 2, 3, 4]  # The labels (classes) you want explanations for\n",
        ")\n",
        "\n",
        "# Visualize the explanation for a specific class (e.g., class 2)\n",
        "exp.show_in_notebook(text=True)\n",
        "\n",
        "# Save the explanation as an HTML file (optional)\n",
        "exp.save_to_file('lime_explanation.html')\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-07T17:12:18.11799Z",
          "iopub.execute_input": "2025-01-07T17:12:18.118304Z",
          "iopub.status.idle": "2025-01-07T17:12:23.41982Z",
          "shell.execute_reply.started": "2025-01-07T17:12:18.118277Z",
          "shell.execute_reply": "2025-01-07T17:12:23.4178Z"
        },
        "id": "IPFOjWaYBVNX",
        "outputId": "100c160e-220b-44a7-b552-760a07cf162e"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Requirement already satisfied: lime in /usr/local/lib/python3.10/dist-packages (0.2.0.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.13.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.5)\nRequirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\nRequirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.24.0)\nRequirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.3)\nRequirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (10.4.0)\nRequirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.35.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.8.30)\nRequirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.1)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (0.4)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.3.0)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.53.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.7)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-9e4835af33f1>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Generate LIME explanation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m exp = explainer.explain_instance(\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mexample_text\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mlime_predict\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Pass the prediction function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/lime_text.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    411\u001b[0m                                         mask_string=self.mask_string))\n\u001b[1;32m    412\u001b[0m         \u001b[0mdomain_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextDomainMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m         data, yss, distances = self.__data_labels_distances(\n\u001b[0m\u001b[1;32m    414\u001b[0m             \u001b[0mindexed_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             distance_metric=distance_metric)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lime/lime_text.py\u001b[0m in \u001b[0;36m__data_labels_distances\u001b[0;34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minactive\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0minverse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_removing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minactive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverse_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-9e4835af33f1>\u001b[0m in \u001b[0;36mlime_predict\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Get model predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1203\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1205\u001b[0;31m         outputs = self.roberta(\n\u001b[0m\u001b[1;32m   1206\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m         )\n\u001b[0;32m--> 834\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 )\n\u001b[1;32m    521\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    523\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    412\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     ) -> Tuple[torch.Tensor]:\n\u001b[0;32m--> 338\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/xlm_roberta/modeling_xlm_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 78.12 MiB is free. Process 36608 has 14.66 GiB memory in use. Of the allocated memory 14.24 GiB is allocated by PyTorch, and 300.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ],
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 314.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 78.12 MiB is free. Process 36608 has 14.66 GiB memory in use. Of the allocated memory 14.24 GiB is allocated by PyTorch, and 300.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "1FNTr6MYBVNX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FyKRppnJBVNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M2h7doBOBVNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, GPT2Tokenizer, GPT2LMHeadModel\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Data cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\u0980-\\u09FFa-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# GAN-based Synthetic Data Generation\n",
        "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model_gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Set pad_token_id explicitly for GPT-2\n",
        "tokenizer_gpt2.pad_token = tokenizer_gpt2.eos_token  # Set pad_token to eos_token to prevent warnings\n",
        "\n",
        "def generate_synthetic_text(prompt, max_length=50):\n",
        "    input_ids = tokenizer_gpt2.encode(prompt, return_tensors=\"pt\")\n",
        "    attention_mask = input_ids != tokenizer_gpt2.pad_token_id  # Generate attention mask\n",
        "    outputs = model_gpt2.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        pad_token_id=tokenizer_gpt2.pad_token_id,\n",
        "    )\n",
        "    return tokenizer_gpt2.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "# Generate synthetic comments\n",
        "synthetic_data = []\n",
        "for label, count in label_mapping.items():\n",
        "    for _ in range(100):  # Adjust the number of synthetic samples as needed\n",
        "        prompt = f\"Generate a {label} comment: \"\n",
        "        comment = generate_synthetic_text(prompt)\n",
        "        synthetic_data.append({\"comment\": comment, \"label\": label})\n",
        "\n",
        "# Convert synthetic data to DataFrame\n",
        "synthetic_df = pd.DataFrame(synthetic_data)\n",
        "synthetic_df['label_encoded'] = synthetic_df['label'].map(label_mapping)\n",
        "synthetic_df['comment'] = synthetic_df['comment'].apply(clean_text)\n",
        "\n",
        "# Combine synthetic data with train_data\n",
        "augmented_train_data = pd.concat([train_data, synthetic_df], ignore_index=True)\n",
        "\n",
        "# Prepare datasets and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-large\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "train_dataset = BanglaDataset(augmented_train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Define optimizer, loss function, and learning rate scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "learning_rate = 2e-5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix({\"accuracy\": f\"{(correct / total):.4f}\"})\n",
        "\n",
        "    train_accuracy = correct / total\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    val_loss /= len(val_dataloader)\n",
        "\n",
        "    # Print epoch summary\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} ━ {epoch_time:.1f}s - accuracy: {train_accuracy:.4f} - loss: {train_loss:.4f} - val_accuracy: {val_accuracy:.4f} - val_loss: {val_loss:.4f} - learning_rate: {learning_rate:.4f}\")\n",
        "\n",
        "# Evaluate the model and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "IqiEIA-bBVNY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, GPT2Tokenizer, GPT2LMHeadModel\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Check if GPU is available\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available and being used.\")\n",
        "    print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"GPU is not available. Using CPU instead.\")\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Data cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^ঀ-৿a-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# GAN-based Synthetic Data Generation\n",
        "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model_gpt2 = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Set pad_token_id explicitly for GPT-2\n",
        "tokenizer_gpt2.pad_token = tokenizer_gpt2.eos_token  # Set pad_token to eos_token to prevent warnings\n",
        "\n",
        "def generate_synthetic_text(prompt, max_length=50):\n",
        "    input_ids = tokenizer_gpt2.encode(prompt, return_tensors=\"pt\")\n",
        "    attention_mask = input_ids != tokenizer_gpt2.pad_token_id  # Generate attention mask\n",
        "    outputs = model_gpt2.generate(\n",
        "        input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=max_length,\n",
        "        num_return_sequences=1,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        pad_token_id=tokenizer_gpt2.pad_token_id,\n",
        "    )\n",
        "    return tokenizer_gpt2.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "# Generate synthetic comments\n",
        "synthetic_data = []\n",
        "for label, count in label_mapping.items():\n",
        "    for _ in range(100):  # Adjust the number of synthetic samples as needed\n",
        "        prompt = f\"Generate a {label} comment: \"\n",
        "        comment = generate_synthetic_text(prompt)\n",
        "        synthetic_data.append({\"comment\": comment, \"label\": label})\n",
        "\n",
        "# Convert synthetic data to DataFrame\n",
        "synthetic_df = pd.DataFrame(synthetic_data)\n",
        "synthetic_df['label_encoded'] = synthetic_df['label'].map(label_mapping)\n",
        "synthetic_df['comment'] = synthetic_df['comment'].apply(clean_text)\n",
        "\n",
        "# Combine synthetic data with train_data\n",
        "augmented_train_data = pd.concat([train_data, synthetic_df], ignore_index=True)\n",
        "\n",
        "# Prepare datasets and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-large\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = BanglaDataset(augmented_train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# Define optimizer, loss function, and learning rate scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "learning_rate = 2e-5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix({\"accuracy\": f\"{(correct / total):.4f}\"})\n",
        "\n",
        "    train_accuracy = correct / total\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    val_loss /= len(val_dataloader)\n",
        "\n",
        "    # Print epoch summary\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} ━ {epoch_time:.1f}s - accuracy: {train_accuracy:.4f} - loss: {train_loss:.4f} - val_accuracy: {val_accuracy:.4f} - val_loss: {val_loss:.4f} - learning_rate: {learning_rate:.4f}\")\n",
        "\n",
        "# Evaluate the model and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "_DDeCwnfBVNY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch import nn, optim\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Data cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\u0980-\\u09FFa-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Setup model, tokenizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-large\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=16)\n",
        "\n",
        "# GAN for Synthetic Data Generation\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(z_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, output_dim),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# GAN setup\n",
        "z_dim = 100\n",
        "output_dim = 300  # Approximate length of a synthetic comment\n",
        "generator = Generator(z_dim, output_dim).to(device)\n",
        "discriminator = Discriminator(output_dim).to(device)\n",
        "\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=2e-4)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=2e-4)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Generate synthetic data with GAN\n",
        "synthetic_data = []\n",
        "generator.eval()\n",
        "for _ in range(500):  # Generate 500 synthetic comments\n",
        "    z = torch.randn(1, z_dim).to(device)  # Random noise for GAN input\n",
        "    with torch.no_grad():\n",
        "        generated_comment = generator(z).cpu().numpy().flatten()\n",
        "        # Convert the GAN output to a string (interpret as characters)\n",
        "        synthetic_comment = ''.join([chr(int(abs(i) % 1114111)) for i in generated_comment])  # Handle valid Unicode range\n",
        "        synthetic_data.append({\"comment\": synthetic_comment, \"label_encoded\": 0})  # Assuming \"not bully\"\n",
        "\n",
        "# Convert synthetic data to DataFrame\n",
        "synthetic_df = pd.DataFrame(synthetic_data)\n",
        "\n",
        "# Combine synthetic data with the training data\n",
        "train_data = pd.concat([train_data, synthetic_df], ignore_index=True)\n",
        "\n",
        "# Redefine training dataset and dataloader\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Define optimizer, loss function, and learning rate scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop with formatted output\n",
        "epochs = 5\n",
        "learning_rate = 2e-5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            \"accuracy\": f\"{(correct / total):.4f}\",\n",
        "            \"loss\": f\"{(train_loss / (total / train_dataloader.batch_size)):.4f}\",\n",
        "        })\n",
        "\n",
        "    train_accuracy = correct / total\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    val_loss /= len(val_dataloader)\n",
        "\n",
        "    # Print epoch summary\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} ━ {epoch_time:.1f}s - accuracy: {train_accuracy:.4f} - loss: {train_loss:.4f} - val_accuracy: {val_accuracy:.4f} - val_loss: {val_loss:.4f} - learning_rate: {learning_rate:.4f}\")\n",
        "\n",
        "# Evaluate the model and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Omf_mB8eBVNc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install git+https://github.com/csebuetnlp/normalizer\n",
        "!pip install transformers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import time\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "import shap\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Data cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\u0980-\\u09FFa-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "\n",
        "# Setup model, tokenizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"xlm-roberta-large\", num_labels=len(label_mapping)\n",
        ").to(device)\n",
        "\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8)\n",
        "\n",
        "# Define optimizer, loss function, and learning rate scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "epochs = 1\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1}/{epochs}\")\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            \"accuracy\": f\"{(correct / total):.4f}\",\n",
        "            \"loss\": f\"{(train_loss / (total / train_dataloader.batch_size)):.4f}\",\n",
        "        })\n",
        "\n",
        "    train_accuracy = correct / total\n",
        "    train_loss /= len(train_dataloader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct / total\n",
        "    val_loss /= len(val_dataloader)\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} ━ {epoch_time:.1f}s - accuracy: {train_accuracy:.4f} - loss: {train_loss:.4f} - val_accuracy: {val_accuracy:.4f} - val_loss: {val_loss:.4f}\")\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:19:56.02079Z",
          "iopub.execute_input": "2025-01-30T09:19:56.021094Z",
          "iopub.status.idle": "2025-01-30T09:20:46.720853Z",
          "shell.execute_reply.started": "2025-01-30T09:19:56.021071Z",
          "shell.execute_reply": "2025-01-30T09:20:46.719387Z"
        },
        "id": "my4lBTG-BVNd",
        "outputId": "50dadb8e-3a67-4a52-cc24-a44c948d2eba",
        "colab": {
          "referenced_widgets": [
            "2c258ceaa5974f76b95feae4e48ea10d",
            "a3b9b666f5de47a6ac14161e26e83af9",
            "9965db2755484407be8de84058e0bd4b",
            "2e1819b8185f4647becadc06badfd1a3",
            "82f11523341441e88b3da4005dab712a"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting git+https://github.com/csebuetnlp/normalizer\n  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-48_15ju5\n  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer /tmp/pip-req-build-48_15ju5\n  Resolved https://github.com/csebuetnlp/normalizer to commit d405944dde5ceeacb7c2fd3245ae2a9dea5f35c9\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from normalizer==0.0.1) (2024.9.11)\nRequirement already satisfied: emoji==1.4.2 in /usr/local/lib/python3.10/dist-packages (from normalizer==0.0.1) (1.4.2)\nRequirement already satisfied: ftfy==6.0.3 in /usr/local/lib/python3.10/dist-packages (from normalizer==0.0.1) (6.0.3)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.2.13)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c258ceaa5974f76b95feae4e48ea10d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3b9b666f5de47a6ac14161e26e83af9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9965db2755484407be8de84058e0bd4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e1819b8185f4647becadc06badfd1a3"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "`clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82f11523341441e88b3da4005dab712a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nEpoch 1/1:   1%|          | 25/3520 [00:20<47:59,  1.21it/s, accuracy=0.3250, loss=1.5030]\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-769f5082894a>\u001b[0m in \u001b[0;36m<cell line: 92>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN+XLM_ROBERTa base"
      ],
      "metadata": {
        "id": "8UUZPukoBVNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/csebuetnlp/normalizer\n",
        "!pip install transformers\n",
        "!pip install imbalanced-learn\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from sklearn.utils import resample\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Advanced Data Cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^ঀ-৿a-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define GAN-based synthetic data generation\n",
        "class GANGenerator(torch.nn.Module):\n",
        "    def __init__(self, noise_dim, output_dim):\n",
        "        super(GANGenerator, self).__init__()\n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(noise_dim, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, output_dim),\n",
        "            torch.nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.fc(noise)\n",
        "\n",
        "def generate_synthetic_data(train_data, label_mapping, num_samples=500):\n",
        "    noise_dim = 100\n",
        "    text_length = 50\n",
        "    generator = GANGenerator(noise_dim, text_length).train()\n",
        "\n",
        "    synthetic_data = []\n",
        "    for label, encoded_label in label_mapping.items():\n",
        "        for _ in range(num_samples):\n",
        "            noise = torch.randn(1, noise_dim)\n",
        "            fake_text = generator(noise).detach().numpy()\n",
        "            text = ''.join([chr(int(abs(char)) % 1114111) for char in fake_text[0]])\n",
        "            text = ''.join([char if char.isprintable() else ' ' for char in text])  # Clean non-printable chars\n",
        "            synthetic_data.append({'comment': text, 'label': label, 'label_encoded': encoded_label})\n",
        "    return pd.DataFrame(synthetic_data)\n",
        "\n",
        "synthetic_data = generate_synthetic_data(train_data, label_mapping)\n",
        "train_data = pd.concat([train_data, synthetic_data], ignore_index=True)\n",
        "\n",
        "# Oversampling function using SMOTE for text data\n",
        "def oversample_data(data, label_mapping):\n",
        "    max_count = data['label_encoded'].value_counts().max()\n",
        "    oversampled_data = []\n",
        "\n",
        "    for label, encoded_label in label_mapping.items():\n",
        "        class_data = data[data['label_encoded'] == encoded_label]\n",
        "        while len(class_data) < max_count:\n",
        "            class_data = pd.concat([class_data, class_data], ignore_index=True)  # Oversampling by duplication\n",
        "        oversampled_data.append(class_data)\n",
        "\n",
        "    return pd.concat(oversampled_data, ignore_index=True)\n",
        "\n",
        "# Oversample training data\n",
        "train_data_oversampled = oversample_data(train_data, label_mapping)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Logging function for loss and accuracy\n",
        "def log_epoch_performance(epoch, train_loss, train_acc, valid_loss, valid_acc):\n",
        "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\\n\")\n",
        "\n",
        "# Training function with progress bar that shows loss and accuracy\n",
        "# Training function with progress bar that shows loss and accuracy\n",
        "def train(model, dataloader, optimizer, scheduler, criterion):\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\", ncols=100)  # Create progress bar instance\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Update progress bar with loss and accuracy\n",
        "        avg_loss = train_loss / (len(dataloader) + 1e-5)\n",
        "        avg_acc = correct / (total + 1e-5)\n",
        "        progress_bar.set_postfix({\"Loss\": avg_loss, \"Accuracy\": avg_acc})  # Update progress bar\n",
        "\n",
        "    return train_loss / len(dataloader), correct / total\n",
        "\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    valid_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluation\", ncols=100):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return valid_loss / len(dataloader), correct / total\n",
        "\n",
        "# Setup model, tokenizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglishbert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"csebuetnlp/banglishbert\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "train_dataset = BanglaDataset(train_data_oversampled, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Define optimizer, scheduler, and loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6)\n",
        "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, scheduler, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_dataloader, criterion)\n",
        "    log_epoch_performance(epoch, train_loss, train_acc, valid_loss, valid_acc)\n",
        "\n",
        "# Evaluate the model with confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:35:53.84246Z",
          "iopub.execute_input": "2025-01-30T09:35:53.842831Z",
          "iopub.status.idle": "2025-01-30T09:37:07.59017Z",
          "shell.execute_reply.started": "2025-01-30T09:35:53.842798Z",
          "shell.execute_reply": "2025-01-30T09:37:07.588706Z"
        },
        "id": "M3Ows4n8BVNd",
        "outputId": "56131460-c188-4cdb-d9d0-8f69f6725a92"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting git+https://github.com/csebuetnlp/normalizer\n  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-f70a_ig1\n  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer /tmp/pip-req-build-f70a_ig1\n  Resolved https://github.com/csebuetnlp/normalizer to commit d405944dde5ceeacb7c2fd3245ae2a9dea5f35c9\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from normalizer==0.0.1) (2024.9.11)\nRequirement already satisfied: emoji==1.4.2 in /usr/local/lib/python3.10/dist-packages (from normalizer==0.0.1) (1.4.2)\nRequirement already satisfied: ftfy==6.0.3 in /usr/local/lib/python3.10/dist-packages (from normalizer==0.0.1) (6.0.3)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.2.13)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.3)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.13.1)\nRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "`clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\nSome weights of ElectraForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglishbert and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 1/10\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training:   4%|▉                     | 79/1891 [00:57<22:00,  1.37it/s, Loss=0.0668, Accuracy=0.255]\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5283f8755f06>\u001b[0m in \u001b[0;36m<cell line: 193>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nEpoch {epoch + 1}/{epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mlog_epoch_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-5283f8755f06>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, scheduler, criterion)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# Update progress bar with loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "HsYR4DibBVNe"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN+BanglihBERT"
      ],
      "metadata": {
        "id": "qBpf-vKsBVNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/csebuetnlp/normalizer\n",
        "!pip install transformers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "\n",
        "# Load and preprocess dataset\n",
        "file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'  # Replace with actual dataset path\n",
        "data = pd.read_excel(file_path)\n",
        "data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "# Encode labels\n",
        "label_mapping = {\"not bully\": 0, \"sexual\": 1, \"threat\": 2, \"troll\": 3, \"religious\": 4}\n",
        "data['label'] = data['label'].str.lower().str.strip()\n",
        "data['label_encoded'] = data['label'].map(label_mapping)\n",
        "\n",
        "# Advanced Data Cleaning\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^ঀ-৿a-zA-Z0-9\\s]', '', text)  # Remove non-Bangla/non-English characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
        "    return text\n",
        "\n",
        "data['comment'] = data['comment'].apply(clean_text)\n",
        "\n",
        "# Split dataset into train, validation, and test sets\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, stratify=data['label_encoded'], random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.2, stratify=train_data['label_encoded'], random_state=42)\n",
        "\n",
        "# Define GAN-based synthetic data generation\n",
        "class GANGenerator(torch.nn.Module):\n",
        "    def __init__(self, noise_dim, output_dim):\n",
        "        super(GANGenerator, self).__init__()\n",
        "        self.fc = torch.nn.Sequential(\n",
        "            torch.nn.Linear(noise_dim, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, output_dim),\n",
        "            torch.nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise):\n",
        "        return self.fc(noise)\n",
        "\n",
        "def generate_synthetic_data(train_data, label_mapping, num_samples=500):\n",
        "    noise_dim = 100\n",
        "    text_length = 50\n",
        "    generator = GANGenerator(noise_dim, text_length).train()\n",
        "\n",
        "    synthetic_data = []\n",
        "    for label, encoded_label in label_mapping.items():\n",
        "        for _ in range(num_samples):\n",
        "            noise = torch.randn(1, noise_dim)\n",
        "            fake_text = generator(noise).detach().numpy()\n",
        "            text = ''.join([chr(int(abs(char)) % 1114111) for char in fake_text[0]])\n",
        "            text = ''.join([char if char.isprintable() else ' ' for char in text])  # Clean non-printable chars\n",
        "            synthetic_data.append({'comment': text, 'label': label, 'label_encoded': encoded_label})\n",
        "    return pd.DataFrame(synthetic_data)\n",
        "\n",
        "synthetic_data = generate_synthetic_data(train_data, label_mapping)\n",
        "train_data = pd.concat([train_data, synthetic_data], ignore_index=True)\n",
        "\n",
        "# Define custom dataset class\n",
        "class BanglaDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length):\n",
        "        self.comments = data['comment'].tolist()\n",
        "        self.labels = data['label_encoded'].tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comments)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.comments[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels': torch.tensor(label, dtype=torch.long),\n",
        "        }\n",
        "\n",
        "# Logging function for loss and accuracy\n",
        "def log_epoch_performance(epoch, train_loss, train_acc, valid_loss, valid_acc):\n",
        "    print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\\n\")\n",
        "\n",
        "# Training function\n",
        "def train(model, dataloader, optimizer, scheduler, criterion):\n",
        "    model.train()\n",
        "    train_loss, correct, total = 0, 0, 0\n",
        "    for batch in tqdm(dataloader, desc=\"Training\"):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        loss = criterion(outputs.logits, labels)\n",
        "        train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.logits, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "    return train_loss / len(dataloader), correct / total\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    valid_loss, correct, total = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluation\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            loss = criterion(outputs.logits, labels)\n",
        "            valid_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return valid_loss / len(dataloader), correct / total\n",
        "\n",
        "# Setup model, tokenizer, and dataloaders\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglishbert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"csebuetnlp/banglishbert\", num_labels=len(label_mapping)).to(device)\n",
        "\n",
        "train_dataset = BanglaDataset(train_data, tokenizer, max_length=128)\n",
        "val_dataset = BanglaDataset(val_data, tokenizer, max_length=128)\n",
        "test_dataset = BanglaDataset(test_data, tokenizer, max_length=128)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=64)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Define optimizer, scheduler, and loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-6)\n",
        "scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * 3)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "    train_loss, train_acc = train(model, train_dataloader, optimizer, scheduler, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, val_dataloader, criterion)\n",
        "    log_epoch_performance(epoch, train_loss, train_acc, valid_loss, valid_acc)\n",
        "\n",
        "# Evaluate the model and plot confusion matrix\n",
        "def evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping):\n",
        "    model.eval()\n",
        "    true_labels, pred_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            _, predicted = torch.max(outputs.logits, 1)\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "            pred_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(\"\\nClassification Report:\\n\")\n",
        "    print(classification_report(true_labels, pred_labels, target_names=label_mapping.keys()))\n",
        "\n",
        "    cm = confusion_matrix(true_labels, pred_labels, normalize='true')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues', xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Evaluate and plot confusion matrix\n",
        "evaluate_model_with_confusion_matrix(model, test_dataloader, label_mapping)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-30T09:17:37.797252Z",
          "iopub.execute_input": "2025-01-30T09:17:37.797562Z",
          "iopub.status.idle": "2025-01-30T09:18:05.923272Z",
          "shell.execute_reply.started": "2025-01-30T09:17:37.797539Z",
          "shell.execute_reply": "2025-01-30T09:18:05.921479Z"
        },
        "id": "sWLahO7FBVNe",
        "outputId": "e9c57571-5427-4493-9003-bd894ffb5b6c",
        "colab": {
          "referenced_widgets": [
            "e9f152af814e4f0c8dcc7e2bf4929f8e",
            "94b45d1646984899bf8a21d523cd9ae2",
            "4d499407822744268dbd658f9b138dd1",
            "dc6ba892bb0646f99f8a8a690391fc4f",
            "a389b9eebb6b4a2eab3bc29cbcce7623"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting git+https://github.com/csebuetnlp/normalizer\n  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-oodgf0tv\n  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer /tmp/pip-req-build-oodgf0tv\n  Resolved https://github.com/csebuetnlp/normalizer to commit d405944dde5ceeacb7c2fd3245ae2a9dea5f35c9\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from normalizer==0.0.1) (2024.9.11)\nCollecting emoji==1.4.2 (from normalizer==0.0.1)\n  Downloading emoji-1.4.2.tar.gz (184 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting ftfy==6.0.3 (from normalizer==0.0.1)\n  Downloading ftfy-6.0.3.tar.gz (64 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.2.13)\nBuilding wheels for collected packages: normalizer, emoji, ftfy\n  Building wheel for normalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for normalizer: filename=normalizer-0.0.1-py3-none-any.whl size=6860 sha256=1effe11098b1e59d43bc7e19e167c7ac5a0de855bd52d1c72ae75a5071f39729\n  Stored in directory: /tmp/pip-ephem-wheel-cache-rzy27jfz/wheels/2e/79/9c/cd96d490298305d51d2da11484bb2c25fd1f759a6906708282\n  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186456 sha256=0c69e0fa23802ad8a8c434e897338b4023a2a82e782a79dd049f21a978df04d7\n  Stored in directory: /root/.cache/pip/wheels/10/f0/fd/4813b1177405693e8da9cdea839f0fb64fde161380e058c827\n  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41930 sha256=9d4e143744d8b0d39889dcb3066e59e7c662a63089ee82a1dfa709df8af22689\n  Stored in directory: /root/.cache/pip/wheels/92/8e/16/c1e4d4d65685d71085e4e27b44d6ed880b0559474c9ee4ff66\nSuccessfully built normalizer emoji ftfy\nInstalling collected packages: emoji, ftfy, normalizer\n  Attempting uninstall: emoji\n    Found existing installation: emoji 2.14.0\n    Uninstalling emoji-2.14.0:\n      Successfully uninstalled emoji-2.14.0\nSuccessfully installed emoji-1.4.2 ftfy-6.0.3 normalizer-0.0.1\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9f152af814e4f0c8dcc7e2bf4929f8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/874 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94b45d1646984899bf8a21d523cd9ae2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/366k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d499407822744268dbd658f9b138dd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc6ba892bb0646f99f8a8a690391fc4f"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a389b9eebb6b4a2eab3bc29cbcce7623"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglishbert and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nEpoch 1/3\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training:   0%|          | 0/480 [00:00<?, ?it/s]\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-c94c0b507504>\u001b[0m in \u001b[0;36m<cell line: 169>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nEpoch {epoch + 1}/{epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0mlog_epoch_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-c94c0b507504>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, scheduler, criterion)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    994\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m         discriminator_hidden_states = self.electra(\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         hidden_states = self.encoder(\n\u001b[0m\u001b[1;32m    911\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 )\n\u001b[1;32m    581\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    583\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    511\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    203\u001b[0m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2574\u001b[0m             \u001b[0mlayer_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2575\u001b[0m         )\n\u001b[0;32m-> 2576\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2578\u001b[0m def rms_norm(\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3826 has 14.72 GiB memory in use. Of the allocated memory 14.48 GiB is allocated by PyTorch, and 117.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ],
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 16.12 MiB is free. Process 3826 has 14.72 GiB memory in use. Of the allocated memory 14.48 GiB is allocated by PyTorch, and 117.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-08T07:10:09.126774Z",
          "iopub.execute_input": "2025-02-08T07:10:09.127132Z",
          "iopub.status.idle": "2025-02-08T07:10:09.133296Z",
          "shell.execute_reply.started": "2025-02-08T07:10:09.127103Z",
          "shell.execute_reply": "2025-02-08T07:10:09.132531Z"
        },
        "id": "OMYWoCVRBVNe",
        "outputId": "55db20e1-d56a-4557-c91d-bf1eab187f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# First, add these cells at the beginning of your notebook to install Bengali fonts\n",
        "!wget https://github.com/google/fonts/raw/main/ofl/notosansbengali/NotoSansBengali%5Bwdth%2Cwght%5D.ttf\n",
        "!mkdir -p ~/.fonts\n",
        "!mv \"NotoSansBengali[wdth,wght].ttf\" ~/.fonts/\n",
        "!fc-cache -f -v\n",
        "\n",
        "# Rest of the imports\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import seaborn as sns\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from matplotlib import font_manager\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from collections import defaultdict\n",
        "\n",
        "# Add the font to matplotlib\n",
        "font_manager.fontManager.addfont(f\"{os.path.expanduser('~')}/.fonts/NotoSansBengali[wdth,wght].ttf\")\n",
        "\n",
        "# Configure matplotlib to use Bengali font\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "plt.rcParams['font.sans-serif'] = ['Noto Sans Bengali']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# Rest of the code remains the same\n",
        "MAX_LENGTH = 128\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "label_mapping = {\n",
        "    \"not bully\": 0,\n",
        "    \"sexual\": 1,\n",
        "    \"threat\": 2,\n",
        "    \"troll\": 3,\n",
        "    \"religious\": 4\n",
        "}\n",
        "\n",
        "def clean_text(text):\n",
        "    # Preserve Bengali characters while cleaning\n",
        "    text = re.sub(r'[^\\u0980-\\u09FF\\s]', '', str(text))\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "def split_bengali_text(text):\n",
        "    # Split Bengali text into words while preserving complete words\n",
        "    words = text.split()\n",
        "    return words\n",
        "\n",
        "class ModelTrainer:\n",
        "    def __init__(self, model, tokenizer, device, label_mapping):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "        self.label_mapping = label_mapping\n",
        "        self.history = {\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': []\n",
        "        }\n",
        "\n",
        "    def create_dataloader(self, texts, labels, batch_size):\n",
        "        # Convert numpy arrays to lists for the tokenizer\n",
        "        if isinstance(texts, np.ndarray):\n",
        "            texts = texts.tolist()\n",
        "\n",
        "        encodings = self.tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=MAX_LENGTH,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        dataset = TensorDataset(\n",
        "            encodings['input_ids'],\n",
        "            encodings['attention_mask'],\n",
        "            torch.tensor(labels)\n",
        "        )\n",
        "        return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    def train_epoch(self, train_dataloader, optimizer, criterion):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for batch in tqdm(train_dataloader, desc=\"Training\"):\n",
        "            input_ids, attention_mask, labels = [b.to(self.device) for b in batch]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = self.model(input_ids, attention_mask=attention_mask).logits\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        avg_loss = total_loss / len(train_dataloader)\n",
        "        accuracy = 100 * correct / total\n",
        "        return avg_loss, accuracy\n",
        "\n",
        "    def evaluate(self, val_dataloader, criterion):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_dataloader, desc=\"Evaluating\"):\n",
        "                input_ids, attention_mask, labels = [b.to(self.device) for b in batch]\n",
        "\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask).logits\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        avg_loss = total_loss / len(val_dataloader)\n",
        "        accuracy = 100 * correct / total\n",
        "        return avg_loss, accuracy, all_preds, all_labels\n",
        "\n",
        "    def plot_training_history(self):\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(self.history['train_loss'], label='Training Loss')\n",
        "        plt.plot(self.history['val_loss'], label='Validation Loss')\n",
        "        plt.title('Model Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(self.history['train_acc'], label='Training Accuracy')\n",
        "        plt.plot(self.history['val_acc'], label='Validation Accuracy')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy (%)')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_confusion_matrix(self, y_true, y_pred):\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=self.label_mapping.keys(),\n",
        "                   yticklabels=self.label_mapping.keys())\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\"\"\"class EnhancedTextExplainer:\n",
        "    def __init__(self, model, tokenizer, label_mapping):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label_mapping = label_mapping\n",
        "        self.reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def predict_proba(self, texts):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            inputs = self.tokenizer(\n",
        "                texts,\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=128,\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(self.device)\n",
        "\n",
        "            outputs = self.model(**inputs)\n",
        "            probas = torch.softmax(outputs.logits, dim=-1)\n",
        "            return probas.cpu().numpy()\n",
        "\n",
        "    def create_prediction_probability_plot(self, probas, ax):\n",
        "        classes = list(self.label_mapping.keys())\n",
        "        y_pos = np.arange(len(classes))\n",
        "\n",
        "        # Create horizontal bar chart for probabilities\n",
        "        bars = ax.barh(y_pos, probas, align='center')\n",
        "        ax.set_yticks(y_pos)\n",
        "        ax.set_yticklabels(classes)\n",
        "        ax.invert_yaxis()\n",
        "        ax.set_xlabel('Probability')\n",
        "        ax.set_title('Prediction probabilities')\n",
        "\n",
        "        # Add probability values at the end of each bar\n",
        "        for i, bar in enumerate(bars):\n",
        "            width = bar.get_width()\n",
        "            ax.text(width, bar.get_y() + bar.get_height()/2,\n",
        "                   f'{probas[i]:.2f}',\n",
        "                   ha='left', va='center', fontsize=8)\n",
        "\n",
        "    def create_word_importance_plot(self, exp_list, ax, is_religious=False):\n",
        "        words = [x[0] for x in exp_list]\n",
        "        scores = [x[1] for x in exp_list]\n",
        "\n",
        "        # Create positive and negative score lists for separate visualization\n",
        "        pos_scores = [max(0, score) for score in scores]\n",
        "        neg_scores = [min(0, score) for score in scores]\n",
        "\n",
        "        # Set up the plot\n",
        "        y_pos = np.arange(len(words))\n",
        "        ax.set_title('NOT Religious' if not is_religious else 'Religious',\n",
        "                    color='blue' if not is_religious else 'red')\n",
        "\n",
        "        # Plot positive and negative bars separately\n",
        "        ax.barh(y_pos, pos_scores, align='center', color='blue', alpha=0.5)\n",
        "        ax.barh(y_pos, neg_scores, align='center', color='red', alpha=0.5)\n",
        "\n",
        "        # Customize appearance\n",
        "        ax.set_yticks(y_pos)\n",
        "        ax.set_yticklabels(words)\n",
        "        ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
        "\n",
        "    def explain_with_lime(self, text, num_features=10, title=\"LIME Explanation for Multi-Class Dataset\"):\n",
        "        # Create explainer\n",
        "        explainer = LimeTextExplainer(\n",
        "            class_names=list(self.label_mapping.keys()),\n",
        "            split_expression=split_bengali_text\n",
        "        )\n",
        "\n",
        "        # Generate explanation\n",
        "        exp = explainer.explain_instance(\n",
        "            text,\n",
        "            self.predict_proba,\n",
        "            num_features=num_features,\n",
        "            num_samples=100\n",
        "        )\n",
        "\n",
        "        # Get prediction probabilities\n",
        "        pred_probs = self.predict_proba([text])[0]\n",
        "\n",
        "        # Create figure with subplots\n",
        "        fig = plt.figure(figsize=(15, 8))\n",
        "        gs = GridSpec(2, 2, width_ratios=[1, 2], height_ratios=[1, 1])\n",
        "\n",
        "        # Prediction probabilities plot\n",
        "        ax_prob = fig.add_subplot(gs[:, 0])\n",
        "        self.create_prediction_probability_plot(pred_probs, ax_prob)\n",
        "\n",
        "        # Word importance plots\n",
        "        ax_imp1 = fig.add_subplot(gs[0, 1])\n",
        "        ax_imp2 = fig.add_subplot(gs[1, 1])\n",
        "\n",
        "        # Get explanation data and create both visualizations\n",
        "        exp_list = exp.as_list()\n",
        "        self.create_word_importance_plot(exp_list, ax_imp1, is_religious=False)\n",
        "        self.create_word_importance_plot(exp_list, ax_imp2, is_religious=True)\n",
        "\n",
        "        # Add the original text at the bottom\n",
        "        plt.figtext(0.5, 0.02, f'Text with highlighted words: {text}',\n",
        "                   ha='center', fontsize=10, bbox=dict(facecolor='white', alpha=0.8))\n",
        "\n",
        "        # Add title\n",
        "        plt.suptitle(title, fontsize=14)\n",
        "\n",
        "        # Adjust layout\n",
        "        plt.tight_layout()\n",
        "        plt.subplots_adjust(top=0.9, bottom=0.1)\n",
        "        plt.show()\"\"\"\n",
        "\n",
        "class EnhancedTextExplainer:\n",
        "    def __init__(self, model, tokenizer, label_mapping):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label_mapping = label_mapping\n",
        "        self.reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def predict_proba(self, texts):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            inputs = self.tokenizer(texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\").to(self.device)\n",
        "            outputs = self.model(**inputs)\n",
        "            probas = torch.softmax(outputs.logits, dim=-1)\n",
        "            return probas.cpu().numpy()\n",
        "\n",
        "    def create_prediction_probability_plot(self, probas, ax):\n",
        "        classes = list(self.label_mapping.keys())\n",
        "        y_pos = np.arange(len(classes))\n",
        "        bars = ax.barh(y_pos, probas, align='center')\n",
        "        ax.set_yticks(y_pos)\n",
        "        ax.set_yticklabels(classes)\n",
        "        ax.invert_yaxis()\n",
        "        ax.set_xlabel('Probability')\n",
        "        ax.set_title('Prediction Probabilities')\n",
        "\n",
        "        for i, bar in enumerate(bars):\n",
        "            width = bar.get_width()\n",
        "            ax.text(width, bar.get_y() + bar.get_height()/2, f'{probas[i]:.2f}',\n",
        "                   ha='left', va='center', fontsize=8)\n",
        "\n",
        "    def create_word_importance_plot(self, exp_list, predicted_class, ax):\n",
        "        words = [x[0] for x in exp_list]\n",
        "        scores = [x[1] for x in exp_list]\n",
        "\n",
        "        y_pos = np.arange(len(words))\n",
        "        ax.set_title(f'Word Importance for Class: {predicted_class}')\n",
        "\n",
        "        # Create positive and negative contribution bars\n",
        "        pos_scores = [max(0, score) for score in scores]\n",
        "        neg_scores = [min(0, score) for score in scores]\n",
        "\n",
        "        # Plot positive contributions in green and negative in red\n",
        "        ax.barh(y_pos, pos_scores, align='center', color='green', alpha=0.5, label='Positive')\n",
        "        ax.barh(y_pos, neg_scores, align='center', color='red', alpha=0.5, label='Negative')\n",
        "\n",
        "        ax.set_yticks(y_pos)\n",
        "        ax.set_yticklabels(words)\n",
        "        ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
        "        ax.set_xlabel('Feature Importance Score')\n",
        "        ax.legend()\n",
        "\n",
        "    def explain_with_lime(self, text, num_features=10, title=\"LIME Explanation\"):\n",
        "        explainer = LimeTextExplainer(\n",
        "            class_names=list(self.label_mapping.keys()),\n",
        "            split_expression=split_bengali_text\n",
        "        )\n",
        "\n",
        "        # Get prediction probabilities and predicted class\n",
        "        pred_probs = self.predict_proba([text])[0]\n",
        "        predicted_class_idx = np.argmax(pred_probs)\n",
        "        predicted_class = list(self.label_mapping.keys())[predicted_class_idx]\n",
        "\n",
        "        # Generate explanation\n",
        "        exp = explainer.explain_instance(\n",
        "            text,\n",
        "            self.predict_proba,\n",
        "            num_features=num_features,\n",
        "            num_samples=100\n",
        "        )\n",
        "\n",
        "        plt.clf()\n",
        "        fig = plt.figure(figsize=(15, 10))\n",
        "        gs = GridSpec(3, 2, figure=fig, width_ratios=[1, 2], height_ratios=[2, 2, 1])\n",
        "\n",
        "        # Prediction probabilities plot\n",
        "        ax_prob = fig.add_subplot(gs[:2, 0])\n",
        "        self.create_prediction_probability_plot(pred_probs, ax_prob)\n",
        "\n",
        "        # Word importance plot for predicted class\n",
        "        ax_imp = fig.add_subplot(gs[0:2, 1])\n",
        "        exp_list = exp.as_list()\n",
        "        self.create_word_importance_plot(exp_list, predicted_class, ax_imp)\n",
        "\n",
        "        # Text with highlighting\n",
        "        ax_text = fig.add_subplot(gs[2, :])\n",
        "        ax_text.set_axis_off()\n",
        "\n",
        "        # Create text with highlighted words\n",
        "        words = text.split()\n",
        "        x_pos = 0.05\n",
        "        y_pos = 0.5\n",
        "\n",
        "        for word in words:\n",
        "            color = None\n",
        "            for exp_word, score in exp_list:\n",
        "                if exp_word in word:\n",
        "                    color = 'lightgreen' if score > 0 else 'lightcoral'\n",
        "                    break\n",
        "\n",
        "            if color:\n",
        "                bbox = dict(facecolor=color, alpha=0.3, edgecolor='none', pad=3)\n",
        "            else:\n",
        "                bbox = None\n",
        "\n",
        "            ax_text.text(x_pos, y_pos, word + ' ', fontsize=10, bbox=bbox, transform=ax_text.transAxes)\n",
        "            x_pos += len(word) * 0.02 + 0.02\n",
        "\n",
        "        plt.suptitle(f\"{title}\\nPredicted Class: {predicted_class}\", fontsize=14)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        return fig\n",
        "\n",
        "def classification_report_with_zero_division(y_true, y_pred, target_names):\n",
        "    return classification_report(y_true, y_pred, target_names=target_names, zero_division=1)\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    file_path = '/kaggle/input/cyberbullying/bangla_online_comments_dataset.xlsx'\n",
        "    data = pd.read_excel(file_path)\n",
        "    data = data.dropna(subset=['comment', 'label'])\n",
        "\n",
        "    data['comment'] = data['comment'].apply(clean_text)\n",
        "    data['label'] = data['label'].str.lower().str.strip()\n",
        "    data['label_encoded'] = data['label'].map(label_mapping)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        data['comment'].values,\n",
        "        data['label_encoded'].values,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=data['label_encoded'].values\n",
        "    )\n",
        "\n",
        "    print(\"Loading XLM-RoBERTa-large model...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        \"xlm-roberta-large\",\n",
        "        num_labels=len(label_mapping)\n",
        "    ).to(device)\n",
        "\n",
        "    trainer = ModelTrainer(model, tokenizer, device, label_mapping)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_dataloader = trainer.create_dataloader(X_train, y_train, BATCH_SIZE)\n",
        "    val_dataloader = trainer.create_dataloader(X_test, y_test, BATCH_SIZE)\n",
        "\n",
        "    # Training setup\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    print(\"\\nStarting training...\")\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss, train_acc = trainer.train_epoch(train_dataloader, optimizer, criterion)\n",
        "\n",
        "        # Evaluate\n",
        "        val_loss, val_acc, val_preds, val_labels = trainer.evaluate(val_dataloader, criterion)\n",
        "\n",
        "        # Store metrics\n",
        "        trainer.history['train_loss'].append(train_loss)\n",
        "        trainer.history['train_acc'].append(train_acc)\n",
        "        trainer.history['val_loss'].append(val_loss)\n",
        "        trainer.history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "    # Plot training history\n",
        "    print(\"\\nPlotting training history...\")\n",
        "    trainer.plot_training_history()\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    print(\"\\nGenerating confusion matrix...\")\n",
        "    trainer.plot_confusion_matrix(val_labels, val_preds)\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(\n",
        "        val_labels,\n",
        "        val_preds,\n",
        "        target_names=label_mapping.keys()\n",
        "    ))\n",
        "\n",
        "    # Initialize the explainer\n",
        "    explainer = EnhancedTextExplainer(model, tokenizer, label_mapping)\n",
        "\n",
        "    # Analyze example text\n",
        "    example_text = data['comment'].iloc[27]\n",
        "    print(example_text)\n",
        "\n",
        "    explainer.explain_with_lime(example_text, title=\"LIME Explanation for Multi-Class Dataset: Sample 1\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-08T07:10:13.826281Z",
          "iopub.execute_input": "2025-02-08T07:10:13.826647Z",
          "iopub.status.idle": "2025-02-08T08:06:12.303535Z",
          "shell.execute_reply.started": "2025-02-08T07:10:13.826616Z",
          "shell.execute_reply": "2025-02-08T08:06:12.302622Z"
        },
        "id": "Zubj3vHCBVNf",
        "outputId": "f2fbb71a-e807-4d84-f2cd-0e39fdc01db3",
        "colab": {
          "referenced_widgets": [
            "02bc817c7397482c95e73a47709edece",
            "45319f79e2db491dbbd3c2925d70d6a5",
            "5e41d08a299846f3854e1c54c6bfa55f",
            "ccf8f2df615f40369e83d92eb3098904",
            "b639e2426c23490285c26a93a1288ad2"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "--2025-02-08 07:10:13--  https://github.com/google/fonts/raw/main/ofl/notosansbengali/NotoSansBengali%5Bwdth%2Cwght%5D.ttf\nResolving github.com (github.com)... 140.82.112.4\nConnecting to github.com (github.com)|140.82.112.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/google/fonts/main/ofl/notosansbengali/NotoSansBengali%5Bwdth%2Cwght%5D.ttf [following]\n--2025-02-08 07:10:14--  https://raw.githubusercontent.com/google/fonts/main/ofl/notosansbengali/NotoSansBengali%5Bwdth%2Cwght%5D.ttf\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 624604 (610K) [application/octet-stream]\nSaving to: ‘NotoSansBengali[wdth,wght].ttf’\n\nNotoSansBengali[wdt 100%[===================>] 609.96K  --.-KB/s    in 0.05s   \n\n2025-02-08 07:10:14 (13.2 MB/s) - ‘NotoSansBengali[wdth,wght].ttf’ saved [624604/624604]\n\n/usr/share/fonts: caching, new cache contents: 0 fonts, 6 dirs\n/usr/share/fonts/X11: caching, new cache contents: 0 fonts, 3 dirs\n/usr/share/fonts/X11/encodings: caching, new cache contents: 0 fonts, 1 dirs\n/usr/share/fonts/X11/encodings/large: caching, new cache contents: 0 fonts, 0 dirs\n/usr/share/fonts/X11/misc: caching, new cache contents: 89 fonts, 0 dirs\n/usr/share/fonts/X11/util: caching, new cache contents: 0 fonts, 0 dirs\n/usr/share/fonts/cMap: caching, new cache contents: 0 fonts, 0 dirs\n/usr/share/fonts/cmap: caching, new cache contents: 0 fonts, 5 dirs\n/usr/share/fonts/cmap/adobe-cns1: caching, new cache contents: 0 fonts, 0 dirs\n/usr/share/fonts/cmap/adobe-gb1: caching, new cache contents: 0 fonts, 0 dirs\n/usr/share/fonts/cmap/adobe-japan1: caching, new cache contents: 0 fonts, 0 dirs\n/usr/share/fonts/cmap/adobe-japan2: caching, new cache contents: 0 fonts, 0 dirs\n/usr/share/fonts/cmap/adobe-korea1: caching, new cache contents: 0 fonts, 0 dirs\n/usr/share/fonts/opentype: caching, new cache contents: 0 fonts, 1 dirs\n/usr/share/fonts/opentype/urw-base35: caching, new cache contents: 35 fonts, 0 dirs\n/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 4 dirs\n/usr/share/fonts/truetype/droid: caching, new cache contents: 1 fonts, 0 dirs\n/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n/usr/share/fonts/truetype/noto: caching, new cache contents: 3 fonts, 0 dirs\n/usr/share/fonts/type1: caching, new cache contents: 0 fonts, 2 dirs\n/usr/share/fonts/type1/gsfonts: caching, new cache contents: 35 fonts, 0 dirs\n/usr/share/fonts/type1/urw-base35: caching, new cache contents: 35 fonts, 0 dirs\n/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n/root/.local/share/fonts: skipping, no such directory\n/root/.fonts: caching, new cache contents: 10 fonts, 0 dirs\n/usr/share/fonts/X11: skipping, looped directory detected\n/usr/share/fonts/cMap: skipping, looped directory detected\n/usr/share/fonts/cmap: skipping, looped directory detected\n/usr/share/fonts/opentype: skipping, looped directory detected\n/usr/share/fonts/truetype: skipping, looped directory detected\n/usr/share/fonts/type1: skipping, looped directory detected\n/usr/share/fonts/X11/encodings: skipping, looped directory detected\n/usr/share/fonts/X11/misc: skipping, looped directory detected\n/usr/share/fonts/X11/util: skipping, looped directory detected\n/usr/share/fonts/cmap/adobe-cns1: skipping, looped directory detected\n/usr/share/fonts/cmap/adobe-gb1: skipping, looped directory detected\n/usr/share/fonts/cmap/adobe-japan1: skipping, looped directory detected\n/usr/share/fonts/cmap/adobe-japan2: skipping, looped directory detected\n/usr/share/fonts/cmap/adobe-korea1: skipping, looped directory detected\n/usr/share/fonts/opentype/urw-base35: skipping, looped directory detected\n/usr/share/fonts/truetype/droid: skipping, looped directory detected\n/usr/share/fonts/truetype/humor-sans: skipping, looped directory detected\n/usr/share/fonts/truetype/liberation: skipping, looped directory detected\n/usr/share/fonts/truetype/noto: skipping, looped directory detected\n/usr/share/fonts/type1/gsfonts: skipping, looped directory detected\n/usr/share/fonts/type1/urw-base35: skipping, looped directory detected\n/usr/share/fonts/X11/encodings/large: skipping, looped directory detected\n/var/cache/fontconfig: cleaning cache directory\n/root/.cache/fontconfig: not cleaning non-existent cache directory\n/root/.fontconfig: not cleaning non-existent cache directory\nfc-cache: succeeded\nUsing device: cuda\nLoading data...\nLoading XLM-RoBERTa-large model...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02bc817c7397482c95e73a47709edece"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45319f79e2db491dbbd3c2925d70d6a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e41d08a299846f3854e1c54c6bfa55f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccf8f2df615f40369e83d92eb3098904"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b639e2426c23490285c26a93a1288ad2"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nStarting training...\n\nEpoch 1/1\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Training: 100%|██████████| 2200/2200 [51:15<00:00,  1.40s/it]\nEvaluating: 100%|██████████| 551/551 [04:07<00:00,  2.22it/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Train Loss: 1.3087 | Train Acc: 42.49%\nVal Loss: 1.5204 | Val Acc: 34.86%\n\nPlotting training history...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1200x400 with 2 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAGGCAYAAACqvTJ0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABhw0lEQVR4nO3de3zP9f//8fub2Wxss4PT2Ewb5pRzjmXIqbBkDiFNCRUfx0gfpeKTCZFEOU4RspwJOfV1WHIOOYTGnM8bso3t9fvDz7vWjG29936x3a6Xy+ty6fV8Pt/P1+P1eq96XB7v5+v1shiGYQgAAAAAAACwo1xmBwAAAAAAAICch6IUAAAAAAAA7I6iFAAAAAAAAOyOohQAAAAAAADsjqIUAAAAAAAA7I6iFAAAAAAAAOyOohQAAAAAAADsjqIUAAAAAAAA7I6iFAAAAAAAAOyOohQAU0RERMhisShPnjw6f/58muMqVKggi8WiDz74wGbH7ty5s/z9/TP8OYvFoqFDh6bZHx0dLYvFomnTpv2L6AAAwOMuO+Y5f7dy5UpZLBaNGzcuw8cBgL+jKAXANLly5VLu3Lk1e/bs+/b/8ssvOnLkiNzc3OwcGQAAwL+TnfOc6dOny83NTdOnTzc7FACPOYpSAExjGIZatWqlWbNm3bd/5syZeu655+Th4WHnyAAAAP6d7JrnXLx4UcuWLdPQoUN14MABbdu2zeyQADzGKEoBMI1hGOratav27dunXbt2peiLj4/XvHnz9Morr9z3s3v37lXLli1VoEAB5c+fX3Xq1NGKFStSjVu2bJkqV64sJycn+fn56ZNPPlGePHlSjYuJidFLL70kLy8vubm5qUWLFvr9999tc6L/8NNPP6lhw4bKnz+/3N3d1bhxY0VFRaUYc+DAAbVq1UoFCxaUi4uLypQpoz59+ig5OTld/QAAwFzZNc+ZNWuW8uXLp//85z+qVKlSmqulli5dqnr16snV1VUeHh6qU6eOTp8+na7+4OBg1atXL9Wc/7w1MSIiQl5eXoqPj1dYWJjc3NxUs2ZNSVJiYqLCw8P11FNPqUCBAvLy8tJzzz2nw4cPp5jz1q1bGjp0qAICApQ3b14VK1ZM/fr109y5c2WxWPTzzz+niuPJJ59UgwYNMnztAKRGUQqAqZo0aSIfHx9FRESkaF+4cKEcHBzUokWLVJ/Zv3+/6tatq7i4OM2YMUPLly/Xk08+qZYtW2rBggXWcRs2bNALL7ygokWLasmSJRo/fryWLFmixYsXp5jvypUrqlOnjvbv369p06YpMjJScXFxeuaZZ3T16lWbnu/atWvVqFEjFShQQPPmzVNkZKTc3NxUv359bd26VdLdJLZJkya6c+eOvv32W61cuVJ9+/ZVgQIFlCtXrof2AwCAR0N2zHOmT5+uDh06yMnJSV26dNG8efN08+bNFGO++eYbhYSEqHLlylq2bJnmzp2rVq1aycfHJ139GXHlyhWFhITIyclJy5Yt01dffSVJypMnj3766Se1bt1aCxYs0JQpU/Tbb7+pQ4cO1s8mJycrJCREU6ZM0TvvvKO1a9dqzJgxeuaZZ/Tiiy/Ky8sr1Xe3b98+7du3T2FhYRmOFcB9GABggpkzZxr3/hM0ePBgw9vb20hMTLT2P/vss0bv3r0NwzCMEiVKGMOGDbP2hYaGGoULFzbi4+NTzBkaGmr4+voaycnJhmEYRrNmzYzChQsbCQkJ1jHXrl0zXFxcjBIlSljb3nvvPcPJyck4ceKEte3SpUuGg4OD8cknn1jbJBn//e9/0zynP/74w5BkTJ06Nc0x1atXNypXrpyiLTk52ahRo4ZRt25dwzAM4+LFi4YkY9asWfed42H9AADAXNkxzzEMw9iyZYshyYiKijIMwzDOnTtn5M6d25g5c6Z1TFJSklGsWDGjbdu2953jYf2GYRj169e35kV/16lTpxTndu86v/rqqw+M+55p06YZkozY2FjDMAxj1apVhiRjxYoV9x0/YMAAo0CBAsatW7esbYMHDzby589v3LhxI13HBPBg/KQOwHRhYWG6dOmSli9fLkk6efKk1q9fn+aS9p9++knNmjWTk5NTivYXX3xRMTExOnTokKS7DxBt1qyZHB0drWPc3d2ty7rvWbdunZ566in5+flZ27y8vBQQEHDfJduZdePGDe3cuVMhISEp2i0Wi1q3bq0tW7bozz//lLe3t1q3bq233npLQ4YM0bFjx1KMf1g/AAB4dGSnPGfatGkqWbKkgoKCdO3aNTk5OSk4ODjFLXxHjx7V6dOn1apVq/vO8bD+zHj11VfTNa5kyZKS7q6uku5eaycnJzVp0uS+47t3765r165ZV58ZhqG5c+eqbdu2ypcv378PHAC37wEwX1BQkGrVqmVdHh0REaFy5cqpWrVq9x1/7do1FS5cOFW7t7e3JOnSpUuSpNjYWBUqVCjVuH+2Xbp0SZs2bZLFYkmxHT582Jq02EJcXJwMw3hg7JcvX5YkRUZG6ssvv9S6detUqlQpNWvWTAcOHLCOf1g/AAB4NGSXPOf69ev67rvv9Mcff8jDw8O6rVu3Tps3b7Y+q+lefPfi/aeH9T9IWs/OvN/1unDhgnr16qXSpUvL2dlZFotFjRo1ShVLgQIF5ODgcN95S5cureDgYM2cOVOStGnTJp08eZJb9wAbuv+/fQBgZ127dlWvXr104cIFRURE6M0330xzbMGCBa0Jzd9duHBB0l9Jjpubm7XI83fXrl1Lse/p6al69erp888/TzU2f/78GTmNB/Ly8pLFYkkzdovFIi8vL0l3XyPdqVMnderUSTt37lSfPn1Uv359HTt2TO7u7g/tBwAAj47skOfMnz9f8fHxWr58eYpVQklJSQoJCdGMGTM0atQo69sE7xebpIf2S3dXkRuGkar93jV4GMMw1LhxY509e1bDhw9XhQoVlC9fPm3fvl3du3dPEUtsbKySkpKUO3fu+87VvXt3de7cWWfPntW8efP0xBNP6Omnn05XHAAejpVSAB4J7du3l4ODg7p3766TJ0+qU6dOaY5t0qSJVq1apVu3bqVo//7771WsWDEFBQVJkmrUqKEff/xRd+7csY65deuWduzYkeJzDRo00OHDh+Xv76/KlSun2AIDA212jk5OTqpfv74WL16cItEyDEOLFi1SrVq15OLikupz1apV04QJE3T58uVUb4xJTz8AADBXdshzpk2bpiZNmuj5559XcHCwdWvUqJHatm2rr7/+Wnfu3FGpUqVUsGBBLV269L7zPKxfulssio6OTrEy6tq1a+m+3fD8+fP69ddf9fbbb6tHjx6qW7euKleurD///DPFuDp16ig+Pl5r1qxJc64XX3xRnp6eioyM1KJFixQWFiaLxZKuOAA8HCulADwS3N3d1bp1a3377bdq3ry5ihYtmubYYcOGacmSJWrevLkGDhyo/Pnza968eVq0aJHmzJljTRTefvttNWnSRG3atNGbb76phIQETZw4MdUb6vr376/Zs2erYcOGGjhwoPz9/RUbG6s9e/aoXr16Gf41bM+ePanefFOyZElVqlRJo0aN0jPPPKPQ0FD17NlTFotFkydP1t69e7Vu3TpJ0rlz59S7d28999xzCggI0K1btzRhwgR5enqqbNmyD+0HAACPlsc9zzlw4IC2bdum77777r79Xbt2VUREhFasWKGQkBANGzZMvXr1UpEiRdSmTRvdunVL27dvV48ePVSwYMGH9jdv3lyLFi1Sz5491alTJ128eFFjxoyRs7Nzuq63t7e3ChYsqLlz56pixYrKmzevNm/erLlz56YY9/zzz6t27doKCwvTyJEjVaZMGZ07d05nzpxR7969Jd39UfGVV17Rp59+qvPnz6f5LDAAmWTmU9YB5Fx/fyvNPT/++KMhyZg3b16K9n++lcYwDOPIkSNGmzZtDA8PDyNfvnxG7dq1jSVLlqQ6zsKFC42KFSsajo6Ohp+fnzF69Gjjs88+S/HmFsMwjLNnzxqvvfaa4ePjYzg4OBienp7G888/b/z666/WMUrn2/fut/Xo0cM67pdffjGaNGliuLm5GW5ubkajRo2MTZs2WfuvX79udO7c2ShcuLCRO3duo0CBAkazZs2MXbt2pasfAACYK7vlOf369TM8PT1TvRHwnuTkZCMgIMBo2bKltW327NlGtWrVDGdnZ8PV1dV4+umnjcuXL6erPzk52fjggw8MPz8/w9HR0ShVqpQxbtw4Y8yYMfd9+97vv/+eKqZNmzYZVatWNRwdHQ1vb2/j1VdfNS5cuGA4OTkZf/zxh3VcXFyc0adPH6N48eJGnjx5jCJFihjvv/9+irkOHz5sSDIaNmx43/MHkHkWw7jPzboAAAAAAEDHjx9XYGCgZs2apZdfftnscIBshWdKAQAAAACQhs8//1yFChVSaGio2aEA2Q7PlAIAAAAA4G/Onj2r6Ohobd68WZ9//rk+++yzdD/TCkD6UZQCAAAAAOBvNm/erM6dO6tAgQJ677339NZbb5kdEpAt8UwpAAAAAAAA2B3PlAIAAAAAAIDdUZQCAAAAAACA3fFMqf8vOTlZZ86ckaurqywWi9nhAACAR5hhGLp+/bp8fHyUK1fO+I2PXAkAAKRXenMlilL/35kzZ+Tr62t2GAAA4DESExOj4sWLmx2GXZArAQCAjHpYrkRR6v9zdXWVdPeCubm5mRwNAAB4lMXFxcnX19eaP+QE5EoAACC90psrUZT6/+4tQ3dzcyPRAgAA6ZKTbmMjVwIAABn1sFwpZzwEAQAAAAAAAI8UilIAAAAAAACwO4pSAAAAAAAAsDueKQUAyJaSkpJ0+/Zts8PAYypPnjzKnTu32WEAAHII8hY8bmyVK1GUAgBkK4Zh6Ny5c7p27ZrZoeAxV6BAARUpUiRHPcwcAGBf5C14nNkiV6IoBQDIVu4ldoUKFZKLiwsFBWSYYRj6888/deHCBUlS0aJFTY4IAJBdkbfgcWTLXImiFAAg20hKSrImdl5eXmaHg8eYs7OzJOnChQsqVKgQt/IBAGyOvAWPM1vlSjzoHACQbdx7FoOLi4vJkSA7uPd3xDM+AABZgbwFjztb5EoUpQAA2Q5L32EL/B0BAOyB/9/gcWWLv12KUgAAAAAAALA7ilIAAGRTb7zxhkaNGpXu8aNGjdIbb7yRhREBAADcH3lLzsSDzgEAMJm/v79OnDhx375hw4bpgw8+yNS8n3/+eYYeOjlo0CAlJSVl6ljpZbFY9OOPP+rZZ5/N0uMAAICskZPylntatWqlkydPas+ePXY5Xk5CUQoAAJPt3r3bmlS1aNFCzzzzjAYNGiTp3z381MEhY/+bt1gsGf4MAADIWXJa3nL27FmtX79eLi4u2rlzp6pVq5blx8xJuH0PAACTeXh4yNvbW97e3nJwcJCLi4t138XFRRs3blSFChW0d+9eVaxYUY6Ojrp69apu3rypHj16yN/fXy4uLqpRo4Z27Nhhnbdz584KCwuTJEVHRytfvnzavHmzqlSpIhcXF1WpUkVbtmyxjh86dKiCg4Ot+xaLRRs3btTTTz8tFxcXlSlTRkuWLEkR+4QJE+Tj46N8+fKpQ4cO+uqrr1SvXr1MXYf4+Hj17t1bhQoVUr58+dS4cWMdPHjQ2n/w4EE1atRIrq6u8vLyUvPmzXX58mVJ0vTp01W6dGnlzZtX/v7++t///pepGAAAwIPltLxl1qxZql27tlq1aqXp06en6v/pp59Uu3ZtOTs7q0iRIvriiy8kSUlJSRoxYoRKlCghZ2dnlStXTsePH1d0dLQsFouOHj2aYh6LxaK1a9dKkiIiItSiRQutW7dOTzzxhLy8vCRJ586dU8eOHVW8eHHlz59fwcHBOnbsmHWOW7duqX///ipatKhcXFxUtWpV/fTTT8qdO7fOnj2b4njVqlXT0KFDH3ju9kBRCgCQrRmGoT8T75iyGYZhs/M4ceKE3njjDU2YMEHHjh2Th4eHXFxcFBQUpIULF+q3336Tv7+/evbsmeYcf/75p3r37q2JEyfqwIEDKl26tDp37vzA47766qv673//q4MHD+q5557Tyy+/rOvXr0uSNmzYoEGDBumTTz7RoUOH1LBhQ/Xr1y/T5zhw4EBt2LBBixcv1oEDB1S+fHk1aNBAV65ckST17NlTFStW1G+//aaffvpJL7zwgry8vHT8+HH16tVLX3zxhY4ePaqZM2fyKyYA4LFE3vKXRyVvmTFjhjp06KD27dvr22+/1a1bt6x9hw4dUrNmzdS6dWsdOXJES5YsUaNGjSRJw4cP15QpUxQREaHDhw9r1KhRKlGiRHoun6S7K9I+/PBDzZ8/X/v27ZMkubq6qkaNGvrhhx+0e/duJScna/DgwdbPvPHGG1q3bp2WLFmiAwcOaMSIEapfv74CAwO1YMEC67jo6Gjt2rVLHTp0SHc8WYU1+gCAbO3W7SSVe3+1Kcf+7aOmcnG0zf9qb9y4offff18NGjSwtlkslhTJVFhYmNq0afPAeQYPHqy6detKuvsshurVq+vy5cvWX+D+qXv37mrWrJmku79Ijh8/XkeOHFG1atU0efJktW/f3pogdu/eXUuXLtW1a9cydX5fffWVVq1apTp16kiSxo0bp+XLl+vbb79Vr169dOvWLbm6usrX11e+vr6qUKGCpLsrrJKTk1WsWDEVL15cxYsXz/DxAQB4FJC3pGR23vJ///d/iomJUWhoqPLnzy9nZ2d9//331jmmTZumWrVqWW9f9PX1lXS3uDhp0iSNHj3aeg38/PweeK7/dObMGa1bt05BQUHWtnz58qW4hu3bt9fnn38uSbp27ZrmzJmjtWvX6qmnnpIklSxZUpLUqVMnzZ8/X//5z38kSQsXLlS5cuWsuZSZWCkFAMBj4umnn06xf+XKFfXr108VKlSQt7e32rdvr4SEhAfOUa5cOes/u7u7S5L1F8SMjj9y5IiqVKmSYnxmk5tjx47pzp07KVY4WSwWVa9eXfv375ckTZkyRXPnzlXVqlX19ddf686dO9YYR4wYodq1a6tTp07avXt3pmIAAAC2kx3ylmnTpqlFixZyd3dX7ty51aFDhxS38B06dOi+q7MvX76sixcv/quV297e3ikKUpIUExOjbt26qWzZsvLy8tLbb7+t+Ph4SdLRo0dT5VL3dO7cWT///LNiYmIk3S1KPQqrpCRWSgEAsjnnPLn120dNTTu2LTk5OaXYDwsL05kzZzRu3Dj5+/tr27Ztevnllx84R0YfQPqg8fdb5p8rV+Z+77p9+7YkKTExMUX7jRs3VKBAAUlS5cqVdfjwYUVGRmrUqFEaO3asNm/eLFdXV7399tvq0qWLJk2apAYNGqhfv34aNmxYpmIBAMAs5C0pmZm3xMbGKjIyUgkJCdYHqhuGIcMwdPz4cT3xxBNp3vKY0Vshb968martn9dPkp5//nkVLVpUX331lYoVK6YFCxboyy+/fOgxn3jiCdWsWVPfffedOnXqpKioKM2YMSNDMWYVilIAgGzNYrHYbCn6o2bdunWaPXu2GjduLEnauHGjXY8fGBiY6tXIhw8fztRcpUuXlqOjo/bt22d9FoNhGNq3b5+aNv0rOc+dO7fat2+v0NBQlSlTRqtXr1ZoaKgkqXDhwvrwww/VoEEDtWjRgqIUAOCxQ96SdTKat8ydO1eurq7atm2bLBaLtb1169aaMWOGRowYodKlS2vnzp2pPuvl5SVPT0/t3Lkz1WqsvHnzSrpb9Lrn3jOjHuTixYvat2+fZs2aZV3x9fdVY0888YRy586tnTt3qn79+qk+37lzZ82ZM0cFChRQpUqVVLp06Yce0x64fQ8AgMdUsWLFtHz5csXExGj16tWaMGGCXY/fvXt3zZs3T3PmzNHJkyc1a9YsrV798OdgREdHa//+/dbtzJkzcnNzU7du3dSvXz9t27ZNJ06c0IABA/Tnn3/qpZdeknT3GVNbt27V6dOntX79el28eFHFixfXkSNHNGXKFP322286efKkfvjhB54rBQDAI+Zxy1umT5+u119/XRUrVlSFChWs25tvvqmIiAglJSWpa9eu2rJli8aNG6dTp05pz5492rRpk3LlyqXXX39dw4YN06ZNmxQTE6NVq1bp/PnzKly4sIoXL67w8HAdP35c27dv18CBAx+62tzd3V358+fXwoULFRMTowULFmj27NnWfi8vL4WGhqpfv37atWuXTpw4oUWLFllv72vfvr127dqlyMhItW/f3jYX1QYoSgEA8Jj66quv9NNPP6lMmTIKDw/XnDlzMn37XGY0bdpUI0aM0IABAxQUFKQlS5aoe/fuD/3cvQTv3vbRRx9JksaPH6/mzZsrJCRE5cqV0969e7V+/Xp5e3tLkk6ePKnQ0FCVLFlS3bt314cffqhatWrJyclJs2fPVu3atVWmTBlt3bpV3377bZaeOwAAyJjHKW/59ddftXv3bvXo0SNVX9euXXX16lWtXr1aTz75pBYvXqyvv/5aAQEBatKkiXX11fDhw9WhQwe1a9dOgYGBGjBggBISEmSxWDRnzhwdPHhQZcuWVefOndW3b1+VKlXqgfE7Ojpq2rRpmjFjhsqWLavZs2enKEpJ0tSpU1W9enU1adJEZcqU0f/+9z/rbX1eXl5q3LixVq1a9UgVpSyGLd/7+BiLi4uTu7u7YmNj5ebmZnY4AIBMiI+P1x9//KGSJUtal0bDvoYMGaKoqCi7L8nPCg/6e8qJeUNOPGcAyErkLebLTnlLegwfPlwrVqzQzz//bJP5bJErsVIKAADYzO7du1WsWDGzwwAAAHionJa3LFy48KEPl7e37PkENQAAkOW2bNmiDRs2qFmzZipYsKAWLlyo1atXa9myZWaHBgAAkEJOzVtu3bqlq1evKiIiQjExMQoLCzM7pBRYKQUAADLF09NT69atU9OmTVWqVClNnjxZkydPVosWLcwOLcdLTExU1apV5e/vL+nuEvo+ffrIx8dHLi4uatq0qaKjo02NEQAAe8qpecuePXvk7++v6dOn67vvvlO+fPnMDikFVkoBAIBMKVu2rDZs2GB2GLiPQYMGKV++fLpy5YokadmyZTp58qRWrFih/Pnzq0ePHnr55Ze1adMmkyMFAMA+cmreUrt2bSUmJpodRppYKQUAAJCNrFixQitXrtTgwYOtbZ06ddKiRYtUpUoVlSpVSgMGDLDZQ04BAAAyi5VSAAAA2cSZM2fUs2dPLV26VLGxsWmOu3TpkooUKWLHyAAAAFJjpRQAAEA2kJycrJdfflmDBw9WlSpV0hx3+/ZtjRkzRr17937gfAkJCYqLi0uxAQAA2BJFKQAAgGwgPDxc7u7u6tWr1wPH9e/fX3nz5lW/fv0eOG7kyJFyd3e3br6+vrYMFwAAgKIUAABAdjB16lQtWrRIFotFFotFDRo00IkTJ2SxWBQRESFJGjt2rJYvX65ly5YpT548D5xvyJAhio2NtW4xMTF2OAsAAJCT8EwpAACAbGDFihUp3q6zaNEiTZ06VStXrpSfn5++/vprjR49Wps2bUrX86ScnJzk5OSUlSEDAIAcjpVSAABkA8HBwRo6dKgkKT4+XkWLFtWJEyfSHD906FAFBwdn+ngnTpxQ0aJFFR8fn+k5YFvlypVT5cqVrZuvr68cHR1VuXJlbd26Vb169dI333wjDw8PXbp0SZcuXVJCQoLZYQMAciDyFtzzSBSlzp07p3r16j3wj2z79u3W5ej3toEDB1r7z58/r5CQELm6uqpYsWKaMGGCHSIHAODfq1ixokaMGJGq/dChQ7JYLDpy5EiG5subN69OnDihEiVK2CpENWrUSEePHrXulyhRQidOnFDevHltdox/8vf317Rp07Js/pxk7Nixun79upo0aaKCBQtat7lz55odGgDgMUPe8mD/+c9/VLBgQd2+fTvLj5UdmF6UioqKUvXq1R/6XIMzZ84oICBAFy9etG4fffSRtb9r166Ki4tTVFSUJk6cqMGDB2v16tVZHT4AAP9ap06d7lscmDt3rqpVq6bSpUtneE5HR0dbhCZJunHjhrZu3Zqlx4DtdevWTdHR0ZKkDRs2yDCMVFtYWJipMQIAHj/kLWlLSEjQnDlz5OzsrKVLl2b58bID04tS27Zt0/jx4/XKK688cNzZs2f1xBNPyNvb27q5uLhIurvSatWqVRo7dqwqVKig1q1bq0uXLvryyy/tcQoAAPwrHTt21MGDB/Xrr7+maJ87d646deokSbp586Z69Oghf39/ubi4qEaNGtqxY8d957tz544sFos2btxobRs7dqx8fHzk4uKil156SUlJSSk+s3LlStWtW1dubm4qXLiw+vfvL8MwdOrUKZUuXVrx8fEqVaqUdd6jR4/KYrFYix6SNGnSJAUEBChv3ryqVKlSimRs48aNKlu2rJYsWaIyZcooX758qlevng4ePJipa5acnKwPPvhAxYsXl7Ozs+rUqaMtW7ZY+8+ePasXXnhBBQoUkLu7u5555hnrL6ZLly7Vk08+KWdnZ/n4+Dz0bXUAAOAv5C1pW7RokTw9PdW9e3dNnz49Vf++ffv07LPPKn/+/PL29ta7775r7fvyyy9VpkwZ5c2bVwEBAYqKipIkWSwWrV27NsU8f19NvnHjRlWoUEF79+5VxYoV5ejoqKtXrz70O0hKStKIESNUokQJOTs7q1y5ctqyZYscHBy0bdu2FMdr06aNOnfu/MBzzyzTi1J9+/ZVaGjoQ8edP39ev/zyi3x8fOTr66vXXntNly5dkiTt3btXDg4Oqly5snV8nTp1tH379qwKGwDwuDAMKfGmOZthpCtEPz8/1atXL8Wvjjt37tSxY8fUoUMHSZKLi4uCgoK0cOFC/fbbb/L391fPnj3TNf8PP/ygd999V+Hh4Tpw4IDq1q2rzz77LMUYFxcXDRgwQL/++qu++eYbTZo0SStWrFDRokW1YsUKSdIvv/yiixcvqm7duqmOERkZqXfffVejRo3SkSNH1LdvX7Vr106bN2+2jvn99981fvx4zZ07V7t375aDg4PeeOONdJ3DP3366aeaNm2aZs6cqcOHDyskJERNmjSxFp7eeecdOTk5ac+ePdq2bZs6d+4sHx8fxcfHq127dhoyZIiOHj2q77///l89owIAAJsib3ms85bp06erQ4cOat++vdasWaNTp05Z+y5evKiGDRuqYsWK2r9/v9auXWuthUREROidd97RJ598ot9//12TJ09WuXLl0nW9pLvPzHrjjTc0YcIEHTt2TB4eHg/9DoYPH64pU6YoIiJChw8f1qhRo1SrVi01bNhQ8+fPt477888/tWrVKut3a2uPzdv3+vXrp2eeeUY+Pj6Kjo7WoEGDFBISoi1btujKlStyd3dXrlx/1di8vLx04cKFNOdLSEhI8XDPuLi4LI0fAGCS239KH/uYc+x3z0iO+dI1tFOnTgoPD9fIkSMl3f21MTg4WEWLFpV091eyfv36WceHhYWpTZs26Zp76tSpatu2rbp06SJJ6tWrlxYvXqw7d+5Yx/y9MOPv729NmFq0aCEPDw9JkoeHh7y9ve97jLFjx6p3797W5Kpr167avHmzxo8fr3r16km6+4vcyJEjVbVqVUlS7969M3372NixYzVixAg1btxYkjR48GCtWbNGX375pcaMGaNbt27J2dlZfn5+ypUrl4KCgiTd/f99UlKSChYsqGLFiqlYsWKZOj4AAFmCvOWxzVuio6O1fv16TZw4UaVKlVLVqlUVERFhfaD7/Pnz5erqqk8//VQWiyXFZydOnKh+/fopJCREkuTr65uua3XPjRs39P7776tBgwbWtgd9B4ZhaNKkSRo9erT1M35+fpKkzp0767///a/Gjh0ri8WiVatWycnJSU2aNMlQTOll+kqp9HJzc1ODBg1UpkwZNW3aVBEREdq6dasOHjyo5OTkVOMdHBxSfdF/N3LkSLm7u1u3jH7pAADYUtu2bXX69GlFRUXJMAzNnz/fugRekq5cuaJ+/fqpQoUK8vb2Vvv27dP95rRjx46pWrVqKdoqVKiQYn/FihVq1KiR/Pz8VKBAAe3evTtDb6g5dOhQqmPUqFFD+/fvT9H291/93N3ddePGjXQf457Y2FidO3fugccbPXq0Dhw4oKCgIE2cOFF//vmnpLv5REREhNq1a6eWLVumuFUAAACkD3lLajNmzFDVqlVVpkwZSXcLdzNnzpTx/1egHTp0SFWrVr1vneJ+8WTU008/nWL/Qd/B5cuXdfHixfse88UXX9SVK1esj0VYuHChWrdunWXP5HpsVkr9071fPK9du6bChQvr2rVrSk5Otq6WunTpUppVUUkaMmSI+vfvb92Pi4ujMAUA2VEel7u//Jl17HTy9PRUs2bNNHfuXN25c0cXL15M8YtiWFiYzpw5o3Hjxsnf31/btm3Tyy+/nO75/76aWFKKF4xs375dL7zwgj766CN9+umncnd3T9et9X93+/ZtJSYmpmi7X+J273mQ/8a9t9k86HglSpTQjh079MMPP+iTTz7RJ598oq1bt6p48eLq1KmTWrZsqalTp+qll15Ss2bNNHPmzH8dFwAA/xp5i6THL29JTk5WRESETp06JQeHu2UWwzCUnJysjRs3qkGDBtbi1P08qO9+bt68marNyckpxf6DvoMHHS9//vwKCQnR/PnzVbNmTS1fvlzfffddhuLLiMe2KHX48GFJUmBgoHLnzq3k5GTt3r3bWunbvn27KlWqlObnnZycUn1pAIBsyGJJ91J0s3Xq1EkDBw6Ug4ODnn/+ebm7u1v71q1bp9mzZ1tvV8vICp8nnnhCe/fuTdF26NAh6z9v3LhR5cqV05AhQyTdTVTOnTtn7b+XGP7zIaN/V6FCBe3bt0/t2rWztu3du1fly5dPd5zp5eXlpaJFi2rfvn166qmnUhzv7/uS1Lx5czVv3lwNGjTQvHnzNHDgQEl3V0wNGDBAbdq0UcmSJTV69OgH/pgFAIBdkLc8lnnLmjVrdP78eW3dulX58+e3tvfq1UvTp09XgwYNVLp0af3www8yDCPVaqnSpUtr586datGiRaq5nZycFBsba90/e/asLl++/NCYHvQdeHl5ydPTUzt37ky1Ck26ewtf9+7dFRISIkdHRzVq1Oihx8usR/b2vaioKPn6+urnn3+WJIWHh2vt2rXWJYLdu3dXx44dVbBgQXl6eio0NFQDBw7UgQMHtHjxYk2dOlWvvfaayWcBAED6tWrVSrGxsZo9e7Y6duyYoq9YsWJavny5YmJitHr1ak2YMCHd87722muaO3eu5s6dq+joaE2fPl0//fRTirmPHz+uLVu26OjRo+rdu3eKXwsLFiwoJycnzZ8/X6dPn06RGN0zYMAATZgwQYsXL9apU6cUERGhBQsW/Os32505c0b79++3bidOnLA+I+GDDz7Q+vXrFRMTo9GjR2vHjh3q3r27pLvPo9iwYYNOnTqln3/+WceOHVPx4sV15coVjRs3Tnv37tXp06e1dOlSubm5ydXV9V/FCQBATkPe8pfp06erbdu2qlWrlipUqGDd+vTpo++//17Xrl1T+/btdeXKFQ0aNEgnT57UgQMHtGbNGklSjx49NH78eK1YsUKnT5/WTz/9pN9//12SVL16dX322Wc6fPiw9u3bp+7du6frVroHfQe5cuXS66+/rmHDhmnTpk2KiYnRqlWrdP78eUlSkyZNdPv2bY0fP15t2rRR7ty5M3Vd0sV4RMycOdOoX7++dX/Lli1GkSJFjK1btxqGYRhjxowx/P39DScnJ6NkyZJGv379jBs3bljHX7582WjdurXh7Oxs+Pj4GKNHj87Q8WNjYw1JRmxsrE3OBwBgf7du3TJ+++0349atW2aHkmldunQx3NzcUp3D+vXrjYCAAMPZ2dkIDg429u7da+TKlcvaX79+feO///2vYRiGcfv2bUOSsWHDBmv/559/bpQsWdJwcXExXnrpJWPGjBnW/+/evn3b6NKli+Hs7GwULVrUGD16tDFo0CBj2LBh1s9PmjTJKFq0qJEvXz5j/fr1xu+//25IMv744w/rmJkzZxqlS5c2nJycjIoVKxqRkZHWvg0bNhiSjNu3b1vbfvzxR+NBqUiJEiUMSSm2pk2bGoZhGMnJycYnn3xi+Pn5GXnz5jVq1qxpbNy40frZe3158uQxihYtagwZMsRISkoyYmNjjWbNmhmenp6Go6OjUaVKFWPNmjX3Pf6D/p5yYt6QE88ZALISeUv2yFsuXrxoODo6WmsXf3fnzh3D19fX+OKLLwzDMIyff/7ZqFOnjpE3b16jQIECxgcffGAYxl95TYkSJYw8efIYJUuWNLZv324YhmHs37/fqFmzpuHk5GT4+fkZX3zxhdG0aVNj6tSpacaanu8gMTHRGDx4sFGkSBHD0dHRKFeunHHixAlrf+/evQ1JKfKrf7JFrmQxjAzevJhNxcXFyd3dXbGxsXJzczM7HABAJsTHx+uPP/5QyZIllTdvXrPDwWPuQX9POTFvyInnDABZibwFj7JvvvlG77zzjmJiYlI94+seW+RKj+ztewAAAAAAALC/77//Xh07dkyzIGUrj+2DzgEAAAAAAGAbt2/f1sWLF7VmzZoMPwsssyhKAQAAAAAA5HDnz59XYGCgPD09NWPGDPn5+WX5MSlKAQAAAAAA5HDFixdXfHy8XY/JM6UAAAAAAABgdxSlAAAAAAAAYHcUpQAA2U5ycrLZISAb4O8IAGAP/P8Gjytb/O3yTCkAQLbh6OioXLly6cyZMypYsKAcHR1lsVjMDguPGcMwlJiYqIsXLypXrlxydHQ0OyQAQDZE3oLHlS1zJYpSAIBsI1euXCpZsqTOnj2rM2fOmB0OHnMuLi7y8/NTrlwsLAcA2B55Cx53tsiVKEoBALIVR0dH+fn56c6dO0pKSjI7HDymcufOLQcHB36xBgBkKfIWPK5slStRlAIAZDsWi0V58uRRnjx5zA4FAADggchbkJOxHh0AAAAAAAB2R1EKAAAAAAAAdkdRCgAAAAAAAHZHUQoAAAAAAAB2R1EKAAAAAAAAdkdRCgAAAAAAAHZHUQoAACCbSUxMVNWqVeXv75+iffny5SpQoIAiIiJMiQsAAODvKEoBAABkM4MGDVK+fPms+4Zh6MMPP9Sbb76pQoUKmRgZAADAXyhKAQAAZCMrVqzQypUrNXjwYGtbYmKijh8/rq1bt8rHx8fE6AAAAP7iYHYAAAAAsI0zZ86oZ8+eWrp0qWJjY63tTk5OmjVrVobmSkhIUEJCgnU/Li7OZnECAABIrJQCAADIFpKTk/Xyyy9r8ODBqlKlyr+eb+TIkXJ3d7duvr6+NogSAADgLxSlAAAAsoHw8HC5u7urV69eNplvyJAhio2NtW4xMTE2mRcAAOAebt8DAADIBqZOnaro6GhZLJYU7RaLRTNnzlRYWFiG5nNycpKTk5MNIwQAAEiJohQAAEA2sGLFCiUmJlr3Fy1apKlTp2rlypXy8/MzMTIAAID7oygFAACQDZQrVy7F/o4dO+To6KjKlSubExAAAMBD8EwpAAAAAAAA2J3FMAzD7CAeBXFxcXJ3d1dsbKzc3NzMDgcAADzCcmLekBPPGQAAZE568wZWSgEAAAAAAMDuKEoBAAAAAADA7ihKAQAAAAAAwO4oSgEAAAAAAMDuKEoBAAAAAADA7ihKAQAAAAAAwO4oSgEAAAAAAMDuKEoBAAAAAADA7ihKAQAAAAAAwO4oSgEAAAAAAMDuKEoBAAAAAADA7ihKAQAAAAAAwO4oSgEAAAAAAMDuKEoBAAAAAADA7ihKAQAAAAAAwO4oSgEAAAAAAMDuKEoBAAAAAADA7ihKAQAAAAAAwO4oSgEAAAAAAMDuKEoBAAAAAADA7ihKAQAAAAAAwO4oSgEAAAAAAMDuKEoBAAAAAADA7ihKAQAAAAAAwO4oSgEAAAAAAMDuKEoBAABkM4mJiapatar8/f2tbStXrlT58uXl7OysmjVr6tdffzUvQAAAAFGUAgAAyHYGDRqkfPnyWfdPnjypNm3aqEuXLtq7d6+qVq2qVq1aKTEx0cQoAQBATvdIFKXOnTunevXqKTg4OF3jR48eLYvFoo0bN1rb3nrrLVkslhTb/v37syZgAACAR9SKFSu0cuVKDR482No2d+5clSpVSoMHD1bp0qX12Wef6fLly/rhhx9MjBQAAOR0pheloqKiVL16deXJkydd47dv367p06eraNGiKdrPnDmjoUOH6uLFi9atbNmyWREyAADAI+nMmTPq2bOn5s+fr/z581vb9+zZoxo1alj3HR0dVb16dW3fvt2MMAEAACQ9AkWpbdu2afz48XrllVceOvb69evq2LGjxo8fL0dHxxR9Z8+eVdmyZeXt7W3dcufOnVVhAwAAPFKSk5P18ssva/DgwapSpUqKvitXrsjT0zNFm5eXly5cuJDmfAkJCYqLi0uxAQAA2JLpRam+ffsqNDQ0XWN79uyp1q1bq1mzZqn6zp8/r0GDBqlQoUJ68sknNWnSpAfORaIFAACyk/DwcLm7u6tXr16p+pKTk1O1OTg4yGKxpDnfyJEj5e7ubt18fX1tGi8AAICD2QGkV0REhI4fP65Zs2bdt3/58uW6deuWnJ2dtWHDBvXv31958uTR66+/ft/xI0eO1IcffpiVIQMAANjN1KlTFR0dnarQZLFYVKxYMfn5+aVov3TpkgICAtKcb8iQIerfv791Py4ujsIUAACwqceiKHXkyBG999572rx5sxwc7h9y+fLlU/zz77//rmnTpqVZlCLRAgAA2cmKFStSvE1v0aJFmjp1qlauXKn169dr5syZ1r47d+5o9+7d6t69e5rzOTk5ycnJKUtjBgAAOdtjUZSaO3euTp06JX9//xTtDRo0UP369VO8he+eoKAgrVq1Ks05SbQAAEB2Uq5cuRT7O3bskKOjoypXriwfHx998MEHGjVqlF588UWNHz9eDg4OatGihUnRAgAAPCZFqR49eigkJMS6n5SUpOrVq2vq1KkKDg6+72cOHz6sUqVK2SlCAACAR1ehQoW0aNEi9e7dWx988IEqVqyoFStWyMXFxezQAABADvbIFqWioqLUrl07LViwQLVq1VKRIkWsfXfu3JEkBQYGKjAwUGfPntWXX36p0NBQFShQQOvXr9eUKVO0ZMkSs8IHAAAwVbdu3dStWzfrfqNGjfTbb7+ZGBEAAEBKj2xRyjAM3blzR4ZhPHSsi4uLdu/erYkTJyo+Pl5BQUGaPXu2GjdubIdIAQAAAAAAkFEWIz1VnxwgLi5O7u7uio2NlZubm9nhAACAR5it8obr169rz549unDhgm7duqUCBQrI399fFSpUsGG0tkGuBAAA0iu9ecMju1IKAAAgO7p165ZmzJihWbNmadeuXZIkd3d3OTs76+rVq7p165ZcXV0VEhKit956SzVr1jQ5YgAAgKyRy+wAAAAAcoqtW7cqKChI06ZNU/v27fXzzz/r1q1bunz5sk6dOqWbN2/qwoULmjNnjhwdHdW0aVO99tprZocNAACQJShKAQAA2ElMTIymTp2q3bt3a8CAAapevbry5MmTYoy3t7datGihadOm6cSJEypYsKBJ0QIAAGQtbt8DAACwk/bt22dovLu7u8LDw7MoGgAAAHOxUgoAAOARceHCBW3fvl1nz541OxQAAIAsR1EKAADgETBmzBhVrlxZffv2VcWKFTVs2DCzQwIAAMhSFKUAAABMsHXr1hT7EydO1KFDh7RlyxZt3LhREyZMMCkyAAAA+6AoBQAAYIL3339f7du315kzZyRJPj4++uqrr7Ru3TrNmjVLJUqUMDlCAACArEVRCgAAwARr165V06ZNVa9ePX3yySeKiIjQ8ePHNWbMGN24cUMLFy40O0QAAIAsRVEKAADAJK+++qp27dqlEydOqE2bNgoNDdUPP/ygyZMn64knnjA7PAAAgCxFUQoAAMAke/fu1Y8//qj27dtr5syZGjp0aIpb+gAAALIzB7MDAAAAyImGDBmi+fPnq3bt2jpw4IAKFSqkqKgoTZs2TXXr1tWbb76pt99+2+wwAQAAsgxFKQAAABN8++23Wrp0qSpVqqTExES5urrq6tWr6tatm1588UUNHTrU7BABAACyFEUpAAAAE5QvX17Dhw9X8+bNtXfvXhUrVkweHh6SJE9PT02aNMnkCAEAALIWz5QCAAAwwZw5c1SzZk3t2LFD3t7e2rRpk9khAQAA2BUrpQAAAEzg4eHBM6MAAECOxkopAAAAOzly5Ihu376doc/s2bMna4IBAAAwGUUpAAAAO1m3bp3KlCmjzz77TBcvXnzg2I0bN6pjx456/vnn7RQdAACAfXH7HgAAgJ288cYbKl68uD788EMNHDhQQUFBqly5sgoWLCgnJyddu3ZNx48f144dO2QYhsLCwnTgwAGzwwYAAMgSFsMwDLODeBTExcXJ3d1dsbGxcnNzMzscAADwCLNF3vDrr79q48aN2rNnjy5evKjExER5eHgoMDBQtWrV0rPPPqu8efPaOPLMI1cCAADpld68gZVSAAAAJnjyySf15JNPmh0GAACAaXimFAAAAAAAAOyOohQAAAAAAADsjqIUAABANpCQkKDw8HAFBgbK0dFRvr6+Gj58uLX/66+/VqlSpeTs7Kynn35ae/fuNTFaAAAAnikFAACQLVy6dElHjhzRlClTFBgYqG3btqlz584KCgqSj4+PXn31VU2dOlWNGjXS5MmT1aRJEx05ckTu7u5mhw4AAHIo3r73//FGGQAAkF62yhtKlCihDh06qH379qpataoNI7yrWrVqCg0N1eXLl7Vr1y6tX79ekmQYhipWrKi+ffuqW7du6ZqLXAkAAKRXevMGbt8DAAAwycCBA/XLL7+oZs2aKlWqlIYOHar9+/f/63nj4+M1a9YsnTp1SqGhobpx40aKhNBisahMmTLcwgcAAExFUQoAAMAkvXv31oYNG3T27FkNHjxYe/bsUY0aNVShQgWNGDFCR44cyfCcAQEBypcvn/73v/9p0aJFKlWqlJ566imtW7dOe/bskSStXLlSP/74o27evJnmPAkJCYqLi0uxAQAA2FKmilJXr15NsX/z5k0tXLhQv/zyi02CAgAAyEm8vb3VrVs3LV++XD///LNKliyp999/X2XLllXNmjW1YMGCdM+1ceNG/fLLL+rdu7datmypDRs26JVXXlGbNm1UvXp15c2bV1OnTlXVqlVVoECBNOcZOXKk3N3drZuvr68NzhQAAOAvmSpKde7cWVOnTpUkJSUlqV69eho8eLCaNm2qzz//3KYBAgAAZHfHjh3Txx9/rEqVKql27dpydHTU999/rxMnTuill15S79699c4776RrLl9fX1WrVk29e/dWhw4dNGHCBOXOnVsRERG6du2azp49q0WLFik6Olply5ZNc54hQ4YoNjbWusXExNjqdAEAACRlsii1bds21a1bV5L07bffKleuXDp8+LC+++47jR8/3pbxAQAAZFujR49W9erVVaZMGa1evVq9evXSmTNn9P3336t169YqXry4+vbtq++//16TJ0/O8Pzx8fFKSkqy7ufPn18eHh7aunWrTp8+rcaNG6f5WScnJ7m5uaXYAAAAbMkhMx9KTEy0Lvf+7LPP9M477yhXrlwqX768Tp8+bcv4AAAAsq2IiAh17txZCxculJ+fX5rjAgICHnr73MqVK3X+/HnVqlVLzs7OWrdunWbPnq2ZM2dKkv744w85OTlp586d+s9//qPevXvL39/flqcDAACQIZkqSj311FMaM2aMXF1dFRsbq9DQUEnSiRMn5O3tbdMAAQAAsqsRI0aoZs2a8vHxSdG+e/dunTt3Ts2bN5ckFSlS5KFv5fPw8NDHH3+svn37KiEhQQEBARo3bpw6duwoSerUqZN27NghPz8/vfbaaxoyZEjWnBQAAEA6ZaooNXHiRPXs2VPx8fGKjIyUxWKRdPe2vnbt2tk0QAAAgOyqb9++mjNnTqqi1O3bt9W9e/cMPcepdu3a2rx5c5r9W7duzXScAAAAWSFTRamgoCBt3LgxVXvfvn3/ZTgAAAA5x4ULF1SyZMlU7cWLF9elS5dMiAgAAMB+MvWg8xUrVujgwYPW/R9//FGtWrXSW2+9patXr9osOAAAgOwsKChI69atS9W+YcMGnvcEAACyvUwVpd59910dPnxYknT27Fm1adNG1apV07Fjx/TWW2/ZNEAAAIDsaujQoerRo4dee+01TZo0SZMmTdJrr72mbt266d133zU7PAAAgCyVqdv3jh49qqpVq0qSJkyYoNDQUA0bNkyHDh1SnTp1bBogAABAdtWmTRt5enpq0qRJmjx5sgzDUOnSpbVo0SI1a9bM7PAAAACyVKaKUm5ubrpx44ZiY2M1bdo06/OlnJyclJiYaMv4AAAAsrUGDRqoQYMGZocBAABgd5kqSnXo0EFt27aVg4ODmjVrpvLly0uS9u7dqyeeeMKmAQIAAGRnV69e1e+//674+PhUfc8884wJEQEAANhHpopSY8aM0TfffKNbt26pa9eu1va8efNqzJgxNgsOAAAgO5s9e7a6deumxMREWSwWGYYh6e7q88qVKysqKsrkCAEAALJOpopSuXPnVlhYWKp2nn0AAACQfsOGDdOIESP0xhtvqHjx4tq5c6eSkpLUp08f9evXz+zwAAAAslSm3r4nSfPmzdNTTz2lfPnyycXFRTVq1NDs2bNtGRsAAEC2du7cOb300kvKly+f8ubNq9u3b6tUqVIaMWIERSkAAJDtZaooNWPGDL3xxhtq1aqVFi5cqG+++UbNmjVT7969NXXqVFvHCAAAkC2VLFlSx48flyT5+vrq119/lSS5urpa2wEAALKrTN2+98knnygiIkIhISHWtjZt2qhGjRp6++239frrr9ssQAAAgOzq1VdfVUxMjCSpY8eOeuutt7R161Zt3rxZ1atXNzk6AACArJWpolR0dLSqVq2aqr1atWrWxAoAAAAP1r9/f+s/9+3bV8nJyVq/fr2qVq2q999/38TIAAAAsl6mbt8LDAzUjz/+mKp9zZo1KlOmzL8OCgAAICdYtmyZ4uPjrfv9+/fX8uXL9dVXX6lYsWImRgYAAJD1MrVS6oMPPtDLL7+sn376SdWqVVNiYqL27dunyMhIRUZG2jpGAACAbKldu3Y6fvy4ihYtanYoAAAAdpeplVKhoaH6v//7P92+fVsRERGaNWuWEhMTtX79ejVv3tzWMQIAAGRLwcHBWrNmjdlhAAAAmCJTK6UkqUaNGvr2229TtB08eFAuLi76888//3VgAAAA2d0XX3yhNm3a6MiRI6pXr56cnJxS9Dds2NCkyAAAALJepotS95OcnJziuQgAAABIW2BgoCRp7969qfosFouSkpLsHRIAAIDd2LQoJd1NoAAAAPBwycnJZocAAABgmkw9UwoAAAAAAAD4NzK0UqpLly4P7L927dq/iQUAACBHeVhu9fXXX9spEgAAAPvL0Eqp3LlzP3Dz8vJ6aHJ1P+fOnVO9evUUHBycrvGjR4+WxWLRxo0brW3nz59XSEiIXF1dVaxYMU2YMCHDcQAAANjTP3Op+Ph47dixQ5GRkSpTpozZ4QEAAGSpDK2Umjlzps0DiIqKUtu2bVWqVCkZhvHQ8du3b9f06dNVtGjRFO1du3bVrVu3FBUVpd9//10dO3ZUmTJl1LRpU5vHDAAAYAtp5Vbvvfeezpw5Y+doAAAA7Mv0Z0pt27ZN48eP1yuvvPLQsdevX1fHjh01fvx4OTo6WtvPnTunVatWaezYsapQoYJat26tLl266Msvv8zK0AEAALJE165dNX/+fLPDAAAAyFKmF6X69u2r0NDQdI3t2bOnWrdurWbNmqVo37t3rxwcHFS5cmVrW506dbR9+3ZbhgoAAGAXZ8+eVWJiotlhAAAAZKkM3b5npoiICB0/flyzZs1K1XflyhW5u7srV66/amxeXl66cOFCmvMlJCQoISHBuh8XF2fbgAEAAB7i/fffT9UWGxurBQsWqHnz5iZEBAAAYD+PRVHqyJEjeu+997R582Y5OKQOOTk5OVWbg4ODLBZLmnOOHDlSH374oU3jBAAAyIhNmzalasubN69ee+01DRo0yISIAAAA7Mf02/fSY+7cuTp16pT8/f1lsVhksVh04sQJNWjQQMHBwSpcuLCuXbuWojh16dIleXt7pznnkCFDFBsba91iYmLscSoAAABWGzZsSLX98MMPGj58uFxdXTM0V0JCgsLDwxUYGChHR0f5+vpq+PDh1v4ZM2YoMDBQTk5OqlChgpYuXWrr0wEAAMiQx2KlVI8ePRQSEmLdT0pKUvXq1TV16lQFBwfL09NTycnJ2r17t6pVqybp7lv6KlWqlOacTk5OcnJyyvLYAQAA0jJ58mQ1atRIpUuXTtG+efNmHTlyRK+++mq657p06ZKOHDmiKVOmKDAwUNu2bVPnzp0VFBSkkiVL6rXXXtOkSZP03HPPaebMmWrbtq1OnjypwoUL2/q0AAAA0uWRXSkVFRUlX19f/fzzzypSpIgqV65s3e4VmwIDAxUYGChPT0+FhoZq4MCBOnDggBYvXqypU6fqtddeM/ksAAAA0jZ8+HDFxsamand1ddW7776bobmKFSumGTNmqGHDhvLz81Pbtm1VoUIFHT16VMePH5eHh4feeOMNlShRQn379lViYqKio6NtdCYAAAAZ98iulDIMQ3fu3JFhGOkaP3nyZHXr1k01atSQh4eHPvroI7Vp0yaLowQAAMi8a9euycfHJ1W7t7f3fYtV6RUfH6/58+fr1KlTCg0NlaurqwzD0O7du1WlShWtXbtWFSpUUJUqVdKcg5fCAACArPbIFKXCwsIUFhZm3a9Tp47Onj1737EODg6pilWenp5auHBhVoYIAABgU5UrV9a8efM0YMCAFO2RkZEqW7ZspuYMCAhQdHS0AgICtGjRIpUqVUqStHLlSrVq1UrNmzfXwYMHtXbtWjk6OqY5Dy+FAQAAWc1ipHcpUjYXFxcnd3d3xcbGys3NzexwAADAI8xWecNPP/2k5s2bq3bt2tbnYu7cuVNbtmzR4sWL1axZswzPGRMTowsXLmjr1q364IMPFBkZqdq1a6tNmzZKSkrSiy++qI8//litWrXSZ599lubbiu+3UsrX15dcCQAAPFR6c6VHZqUUAABATlO/fn3t2rVL06dP18GDB2UYhipVqqTx48erYsWKmZrT19dXvr6+qlatmg4dOqQJEyZo7969Onr0qA4cOCAHBwe1bdtWlSpVUlBQkN588837zsNLYQAAQFajKAUAAGCioKAgjR49Okvmjo+PV1JSko4ePapy5crJweFu6ufh4aHKlStr//79WXJcAACA9Hhk374HAACQ3TVu3FgbNmxI1f7999/rueeey9BcK1eu1MyZM3Xw4EFFR0dr+vTpmj17tjp06KB69erpxx9/1LJly3Tq1ClFRkbqxx9/1LPPPmurUwEAAMgwVkoBAACYZNu2bSpRokSq9ipVqmjTpk0ZmsvDw0Mff/yx+vbtq4SEBAUEBGjcuHHq2LGjJOnkyZPq27evTp06JV9fX40dO1YvvviiTc4DAAAgMyhKAQAAmMTR0VHx8fGp2hMSEqy32qVX7dq1tXnz5jT7Bw0apEGDBmU4RgAAgKzC7XsAAAAmadmypfr06aOYmBhrW0xMjPr376+mTZuaGBkAAEDWoygFAABgkk8//VS3b9+Wv7+/ChUqpEKFCsnf31/Xrl3TZ599ZnZ4AAAAWYrb9wAAAEzi4eGhjRs36sCBAzp06JAMw1Dp0qX15JNPmh0aAABAlqMoBQAAYLLy5curfPny1v0ff/xR06dP17x580yMCgAAIGtx+x4AAMAj4OTJk/rwww9VsmRJtWzZMsMPOgcAAHjckO0AAACYJDExUYsWLdL06dO1bt06SdKAAQM0cOBAFSpUyOToAAAAshYrpQAAAOxs79696tOnj4oWLaq3335bVapU0a5du5QrVy6FhYVRkAIAADkCK6UAAADsrEqVKvLz89OkSZPUrl07WSwWs0MCAACwO1ZKAQAA2FlkZKQqVKigl19+WcHBwZo2bZpiY2PNDgsAAMCuKEoBAADY2Ysvvqjly5crOjpaTZo0UXh4uIoUKaLk5GRFRUXJMAyzQwQAAMhyFKUAAABM4uPjo//+9786evSoVqxYoQ4dOqh379564okn9Mknn5gdHgAAQJaiKAUAAPAIaNiwoebMmaOzZ89q4MCBmj9/vtkhAQAAZCmKUgAAAI8Qd3d3vfXWW9q5c6fZoQAAAGQpilIAAAAAAACwO4pSAAAAAAAAsDuKUgAAAAAAALA7ilIAAAAAAACwO4pSAAAAAAAAsDuKUgAAAAAAALA7ilIAAAAAAACwO4pSAAAAAAAAsDuKUgAAAAAAALA7ilIAAAAAAACwO4pSAAAAAAAAsDuKUgAAAAAAALA7ilIAAADZREJCgsLDwxUYGChHR0f5+vpq+PDhkqTg4GBZLJZUW9euXU2OGgAA5FQOZgcAAAAA27h06ZKOHDmiKVOmKDAwUNu2bVPnzp0VFBSkJUuW6Pbt2ynG161bV/Xq1TMpWgAAkNNRlAIAAMgmihUrphkzZlj3/fz8FB4erqNHj6pt27Ypxm7cuFEXLlzQSy+9ZO8wAQAAJFGUAgAAyJbi4+M1f/58nTp1SqGhoan6P//8c4WFhcnFxeW+n09ISFBCQoJ1Py4uLstiBQAAORNFKQAAgGwmICBA0dHRCggI0KJFi1SqVKkU/SdPntTSpUv122+/pTnHyJEj9eGHH2Z1qAAAIAfjQecAAADZzMaNG/XLL7+od+/eatmypTZs2JCif9KkSWrQoEGqYtXfDRkyRLGxsdYtJiYmq8MGAAA5DCulAAAAshlfX1/5+vqqWrVqOnTokCZMmKAGDRpIuntb37Rp0zRt2rQHzuHk5CQnJyd7hAsAAHIoVkoBAABkY/Hx8UpKSrLuz5kzRy4uLmrZsqWJUQEAALBSCgAAINtYuXKlzp8/r1q1asnZ2Vnr1q3T7NmzNXPmTOuYzz//XD169FDu3LlNjBQAAICiFAAAQLbh4eGhjz/+WH379lVCQoICAgI0btw4dezYUZK0adMmHTx4UN26dTM5UgAAAIpSAAAA2Ubt2rW1efPmNPuffvppJSQk2DEiAACAtPFMKQAAAAAAANgdRSkAAAAAAADYHUUpAAAAAAAA2B1FKQAAAAAAANgdRSkAAAAAAADYHUUpAAAAAAAA2B1FKQAAAAAAANgdRSkAAAAAAADYHUUpAAAAAAAA2B1FKQAAAAAAANgdRSkAAAAAAADYHUUpAAAAAAAA2N0jUZQ6d+6c6tWrp+Dg4DTHbNiwQfXr15eLi4vc3NwUEhKi06dPW/vfeustWSyWFNv+/fvtED0AAAAAAAAyyvSiVFRUlKpXr648efI8cNyqVasUFhamPXv2aNOmTTpz5oy6d+9u7T9z5oyGDh2qixcvWreyZctmdfgAAAAAAADIBAezA9i2bZvGjx+vGzduKCIiIs1xo0aNSrHfpUsXTZw40bp/9uxZtW3bVt7e3lkVKgAAAAAAAGzE9JVSffv2VWhoaLrHG4ah/fv3a/LkyerZs6e1/fz58xo0aJAKFSqkJ598UpMmTcqKcAEAAAAAAGADpq+Uyoj33ntPY8aMkWEY+u9//6t+/fpZ+5YvX65bt27J2dlZGzZsUP/+/ZUnTx69/vrr950rISFBCQkJ1v24uLgsjx8AAAAAAAB3mb5SKiP69++vPXv2aMGCBVq8eHGKlVLly5dX9erVVb58efXq1Us9evTQtGnT0pxr5MiRcnd3t26+vr72OAUAAAAAAADoMStKeXh4qEyZMmrZsqW+/PJLffXVV7p27dp9xwYFBaXZJ0lDhgxRbGysdYuJicmaoAEAAAAAAJDKY3X73t/Fx8dLkpKSku7bf/jwYZUqVSrNzzs5OcnJySlLYgMAAAAAAMCDPbIrpaKiouTr66uff/5ZN2/e1LvvvqtffvlFp0+f1qZNm9SnTx81btxYXl5eOnv2rIYNG6Z9+/YpJiZGs2bN0pQpU9SnTx+zTwMAAAAAAAD38ciulDIMQ3fu3JFhGHJwcNDJkycVEhKiy5cvy9PTU88995xGjx4tSXJxcdHu3bs1ceJExcfHKygoSLNnz1bjxo1NPgsAAAAAAADcj8UwDMPsIB4FcXFxcnd3V2xsrNzc3MwOBwAAPMJyYt6QE88ZAABkTnrzhkf29j0AAAAAAABkXxSlAAAAAAAAYHcUpQAAALKJhIQEhYeHKzAwUI6OjvL19dXw4cOt/cnJyRo1apTKlCkjR0dH1axZ08RoAQBATvfIPugcAAAAGXPp0iUdOXJEU6ZMUWBgoLZt26bOnTsrKChIbdu21TvvvKMlS5ZowoQJqlixopKTk80OGQAA5GAUpQAAALKJYsWKacaMGdZ9Pz8/hYeH6+jRozp58qS++OILHTx4UH5+fiZGCQAAcBe37wEAAGRD8fHxmjVrlk6dOqXQ0FCtWbNGTz75pBYsWCBfX1+VL19eX3/9tdlhAgCAHIyVUgAAANlMQECAoqOjFRAQoEWLFqlUqVKaPHmyDh06pBMnTmj16tXasGGDunbtqtKlS6tWrVqp5khISFBCQoJ1Py4uzp6nAAAAcgCKUgAAANnMxo0bdeHCBW3dulUtW7ZUZGSkrl+/rpIlS2rChAmSpHLlymnevHn6/vvv71uUGjlypD788EN7hw4AAHIQilIAAADZjK+vr3x9fVWtWjUdOnRIEyZMUIkSJeTj45NiXPHixXXlypX7zjFkyBD179/fuh8XFydfX98sjRsAAOQsPFMKAAAgG4uPj1dSUpIqVqyonTt3Kj4+3tp37NixNAtNTk5OcnNzS7EBAADYEkUpAACAbGLlypWaOXOmDh48qOjoaE2fPl2zZ89Whw4dFBoaKsMw1K9fP0VHR2vixInas2ePXnrpJbPDBgAAORS37wEAAGQTHh4e+vjjj9W3b18lJCQoICBA48aNU8eOHSVJq1ev1ltvvaWyZcuqRIkS+u6771SmTBmTowYAADkVRSkAAIBsonbt2tq8eXOa/ZUqVXpgPwAAgD1x+x4AAAAAAADsjqIUAAAAAAAA7I6iFAAAAAAAAOyOohQAAAAAAADsjqIUAAAAAAAA7I6iFAAAAAAAAOyOohQAAAAAAADsjqIUAAAAAAAA7I6iFAAAAAAAAOyOohQAAAAAAADsjqIUAAAAAAAA7I6iFAAAAAAAAOyOohQAAAAAAADsjqIUAAAAAAAA7I6iFAAAAAAAAOyOohQAAAAAAADsjqIUAAAAAAAA7I6iFAAAAAAAAOyOohQAAAAAAADsjqIUAAAAAAAA7I6iFAAAAAAAAOyOohQAAAAAAADsjqIUAAAAAAAA7I6iFAAAAAAAAOyOohQAAAAAAADsjqIUAABANpGQkKDw8HAFBgbK0dFRvr6+Gj58uLU/f/78slgs1q169eomRgsAAHI6B7MDAAAAgG1cunRJR44c0ZQpUxQYGKht27apc+fOCgoKUpMmTXTz5k3t379fhQsXliTlyZPH5IgBAEBORlEKAAAgmyhWrJhmzJhh3ffz81N4eLiOHj2qihUrysnJSeXKlZPFYjExSgAAgLu4fQ8AACAbio+P16xZs3Tq1CmFhobq/PnzSkpKUsmSJVWkSBE1a9ZMe/bsMTtMAACQg7FSCgAAIJsJCAhQdHS0AgICtGjRIpUqVUoBAQFas2aNChcurOvXr2vMmDFq2LChDh48aL2d7+8SEhKUkJBg3Y+Li7PnKQAAgByAlVIAAADZzMaNG/XLL7+od+/eatmypTZs2KBcuXKpQYMGKleunGrWrKk5c+bIwcFBCxcuvO8cI0eOlLu7u3Xz9fW181kAAIDsjqIUAABANuPr66tq1aqpd+/e6tChgyZMmJBqjKOjo0qWLKlr167dd44hQ4YoNjbWusXExGRx1AAAIKfh9j0AAIBsLD4+XklJSanab9++rT/++EOlSpW67+ecnJzk5OSU1eEBAIAcjKIUAABANrFy5UqdP39etWrVkrOzs9atW6fZs2dr5syZmjt3riSpTp06+vPPPxUeHi5XV1e1aNHC5KgBAEBOxe17AAAA2YSHh4emT5+uWrVqKSgoSJ9++qnGjRunjh07ysvLS6NGjVK5cuXUoEED3bhxQ+vWrVPevHnNDhsAAORQFsMwDLODeBTExcXJ3d1dsbGxcnNzMzscAADwCMuJeUNOPGcAAJA56c0bWCkFAAAAAAAAu6MoBQAAAAAAALujKAUAAAAAAAC7oygFAAAAAAAAu6MoBQAAAAAAALujKAUAAAAAAAC7eySKUufOnVO9evUUHByc5pgNGzaofv36cnFxkZubm0JCQnT69Glr//nz5xUSEiJXV1cVK1ZMEyZMsEPkAAAAAAAAyAzTi1JRUVGqXr268uTJ88Bxq1atUlhYmPbs2aNNmzbpzJkz6t69u7W/a9euiouLU1RUlCZOnKjBgwdr9erVWR0+AAAAAAAAMsHB7AC2bdum8ePH68aNG4qIiEhz3KhRo1Lsd+nSRRMnTpR0d6XVqlWrtGPHDlWoUEEVKlRQly5d9OWXX6pp06ZZGT4AAAAAAAAywfSVUn379lVoaGi6xxuGof3792vy5Mnq2bOnJGnv3r1ycHBQ5cqVrePq1Kmj7du3pzlPQkKC4uLiUmwAAAAAAACwD9OLUhnx3nvvycXFRdWrV9dLL72kfv36SZKuXLkid3d35cr11+l4eXnpwoULac41cuRIubu7WzdfX98sjx8AAAAAAAB3PVZFqf79+2vPnj1asGCBFi9ebF0plZycnGqsg4ODLBZLmnMNGTJEsbGx1i0mJibL4gYAAAAAAEBKpj9TKiM8PDzk4eGhMmXKqEiRInrqqacUHh6uwoUL69q1a0pOTraulrp06ZK8vb3TnMvJyUlOTk7WfcMwJInb+AAAwEPdyxfu5Q85AbkSAABIr/TmSo9VUerv4uPjJUlJSUmqWrWqkpOTtXv3blWrVk2StH37dlWqVCnd812/fl2SuI0PAACk2/Xr1+Xu7m52GHZBrgQAADLqYbnSI1uUioqKUrt27bRgwQJVrFhR//vf//TCCy+oWLFiOn78uPr06aPGjRvLy8tLkhQaGqqBAwdq4sSJ+v333zV16lR988036T6ej4+PYmJi5Orq+sDb/nKquLg4+fr6KiYmRm5ubmaHk6Nw7c3F9TcX1988XPsHMwxD169fl4+Pj9mh2A250oPx74x5uPbm4vqbi+tvHq79g6U3V3pki1KGYejOnTsyDEMODg46efKkQkJCdPnyZXl6euq5557T6NGjreMnT56sbt26qUaNGvLw8NBHH32kNm3apPt4uXLlUvHixbPiVLIVNzc3/oUzCdfeXFx/c3H9zcO1T1tOWSF1D7lS+vDvjHm49ubi+puL628ern3a0pMrPTJFqbCwMIWFhVn369Spo7Nnz1r3Z8+e/cDPe3p6auHChVkVHgAAAAAAAGzosXr7HgAAAAAAALIHilJIFycnJw0bNizFGwthH1x7c3H9zcX1Nw/XHsgY/p0xD9feXFx/c3H9zcO1tw2LkZPeZQwAAAAAAIBHAiulAAAAAAAAYHcUpQAAAAAAAGB3FKUAAAAAAABgdxSloJUrV6p8+fJydnZWzZo19euvv6Y59vz58woJCZGrq6uKFSumCRMm3HdcVFSU8uTJow8++CCLos4ebHXt4+Li1KdPH/n4+MjFxUVNmzZVdHS0Hc7g8ZTev2NJGjVqlIoVK6Z8+fKpbdu2unr1aqbmwV9sdf3nzJmjKlWqyNnZWaVLl9bcuXPtEf5jzVbX/p7ExERVrVpV/v7+WRg1YD5yJfOQK5mDXMlc5ErmIl+yMwM52okTJ4y8efMa4eHhxuHDh42ePXsaJUqUMBISEu47vnnz5kZwcLCxb98+Y+HChUbevHmNVatWpRhz9epVIyAgwKhVq5YxbNgwO5zF48mW13727NnGCy+8YOzatcs4cuSI0aBBA6NevXr2PJ3HSnr+jg3DMObPn2/ky5fPWLp0qfHrr78aderUMTp06JDheZCSLa7/pUuXjKeeesqIjIw0YmJijLFjxxq5c+c2Dh8+bO/TeazY6m//nj59+hj16tUzSpQoYYfoAXOQK5mHXMk85ErmIlcyF/mSfVGUyuHCw8ONihUrWvcTEhKM/PnzG4sXL0419uzZs4bFYjF27txpbevevbvxwgsvpBjXtm1b45133jFeeeUVEq0HyIprf8/y5csNBwcH2wedDWTkWjZr1szo3bu3dX/r1q1G7ty5jcuXL2f4O8Fdtrr+9+Pt7W188803tg86m7D1tV++fLlRqlQpY9myZSRZyNbIlcxDrmQOciVzkSuZi3zJ/rh9L4fbs2ePatSoYd13dHRU9erVtX379lRj9+7dKwcHB1WuXNnaVqdOnRRjp06dqtOnT2v48OFZGnd2YOtr/3eXLl1SkSJFbB5zdpCRa/nP7+ipp56SJO3atSvD3wnustX1/6f4+HjdvHlTRYsWtX3Q2YQtr/2ZM2fUs2dPzZ8/X/nz58/awAGTkSuZh1zJHORK5iJXMhf5kv1RlMrhrly5Ik9PzxRtXl5eunDhwn3Huru7K1euXPcde/DgQX300UeaO3euHBwcsjbwbMCW1/7vbt++rTFjxqh37962DzobyMi1/Od3lDt3bhUoUEAXLlzI0Dz4i62u/z+NGzdOgYGBCg4OzpK4swNbXfvk5GS9/PLLGjx4sKpUqWKX2AEzkSuZh1zJHORK5iJXMhf5kv1RlMph5syZo/z581u35OTkVGMcHBxksVhStT9obHx8vDp06KCJEyfKz88vS2J/3GXVtf+n/v37K2/evOrXr59tAs9mbHXdMzIP/pIVf/dbtmxReHi4pkyZoty5c9su2GzGVtc+PDxc7u7u6tWrV5bECZiNXMk85EqPBnIlc5ErmYt8yf74iSaHCQkJUd26da37Q4cO1ZUrV1KMuXTpkgICAlJ9tnDhwrp27ZqSk5OtleNLly7J29tb27Zt06+//qoXXngh1ec+/PBDGYZh2xN5DGXVtf+7sWPHavny5dY3+iC19F7Le2P//h0lJyfr6tWr8vb2lsViSfc8+Iutrv89hw8f1gsvvKAvv/xStWrVyvoTeIzZ6tq/++67io6OTpWcWSwWzZw5U2FhYVl6HkBWI1cyD7nSo4FcyVzkSuYiX7I/VkrlMPnz55e/v791q169un755Rdr/507d7R7925VqlQp1WerVq2q5ORk7d6929q2fft2VapUSdWqVdPu3btTbJUrV1aPHj1SjM/Jsura3/P1119r9OjRWrNmDc9IeID0XMt7/vkd7d27V7dv39aTTz6ZoXnwF1tdf0k6deqUmjRpoqFDh+qll17K+uAfc7a69itWrEjx3/r3339fRYsW1e7du9WqVSu7nAuQlciVzEOu9GggVzIXuZK5yJdMYPaT1mGu8+fPG66urkZ4eLhx5MgR48033zQKFSpk3Lx50zAMwxgwYIBRs2ZN6/h27doZwcHBxv79+41FixYZzs7ORmRk5H3nrlu3Lm+UeQBbXvtly5YZrq6uxpo1a4yLFy9at/j4eFPO7VGX1rXcunWrUbx4cSMqKsowDMNYuXKlkS9fPmPZsmXGvn37jLp16xotWrR46Dx4MFtc/8uXLxvlypUz3nzzzRR/89euXTPz1B55tvrb/7upU6fyNhlka+RK5iFXMg+5krnIlcxFvmRfFKVgrF271ihbtqyRN29eo0aNGsb27dutfX379jWqV69u3b98+bLRunVrw9nZ2fDx8TFGjx6d5rwkWg9nq2sfHBxsSEq1zZw5056n89hI61pu2bLFKFKkiLF161br2HHjxhlFihQx8ufPb4SEhBgXLlx46Dx4MFtc/4iIiPv+zdevX9+MU3ps2Opv/+9IspATkCuZh1zJHORK5iJXMhf5kn1ZDIMb2AEAAAAAAGBfPFMKAAAAAAAAdkdRCgAAAAAAAHZHUQoAAAAAAAB2R1EKAAAAAAAAdkdRCgAAAAAAAHZHUQoAAAAAAAB2R1EKAAAAAAAAdkdRCgAAAAAAAHZHUQoAAAAAAAB2R1EKAGwoLCxMnTt3NjsMAACARxb5EoB7KEoByJbCwsJksVhSbAUKFDA7LAAAgEcG+RIAs1GUApBthYaG6uLFi9bt+PHjZocEAADwSCFfAmAmilIAsi0nJyd5e3tbN09PT0VHR8vZ2Vn/93//p0qVKsnV1VXPPPOMfvvttxSfnTRpkgICApQ3b15VqlRJS5cuTdG/b98+Pfvss8qfP7+8vb317rvvWvty5cqlPn36yNPTUwUKFNDrr7+uO3fu2OWcAQAAMoJ8CYCZKEoByHHi4+P19ttva8qUKdq5c6f8/PzUsGFD3bhxQ5IUGRmpd999V6NGjdKRI0fUt29ftWvXTps3b5YkXbx4UQ0bNlTFihW1f/9+rV27VqGhodb5IyMj5eHhoR07dmj+/PmaM2eOZs2aZcq5AgAAZAb5EgB7sBiGYZgdBADYWlhYmL799lu5uLhY255//nn973//U8mSJbVo0SK98MILkqTr16+rSJEimjVrlkJDQ1W7dm09++yzGj58uPWzr732mmJjYxUZGamJEyfq008/1bFjx2SxWFIdNyoqSocPH7a2tWzZUsWLF9fkyZOz9qQBAAAygHwJgNlYKQUg23r++ee1Z88e6zZu3DhrX+nSpa3/7OrqqsDAQB09elSSdOjQIVWrVi3FXDVq1ND+/fut/VWrVk2VYN1Tvnz5FPvu7u66deuWTc4JAADAlsiXAJjJwewAACCr5MuXT/7+/inaoqOjJUm3b99O0Z6QkKDcuXNb+xITE1P031uqLkkPW2D6918bAQAAHmXkSwDMxEopADnS3x/Uef36df3xxx/WXwMrVKigffv2pRi/d+9e6y96pUuX1q5dux6abAEAADzOyJcAZDWKUgCyrYSEBF26dMm6Xblyxdr38ccfa8uWLfrjjz/0xhtvqGDBgmrSpIkkacCAAZowYYIWL16sU6dOKSIiQgsWLFCvXr0kSe3bt9eVK1c0aNAgnTx5UgcOHNCaNWtMOUcAAIB/g3wJgJkoSgHItiIjI1WwYEHr9sQTT1j73nnnHXXv3l1ly5bV0aNHtWLFCjk7O0uS2rZtq88++0yDBw9WYGCgPv30U82ZM0cNGjSQJBUpUkSrV6/W1q1bVaZMGdWrV09RUVGmnCMAAMC/Qb4EwEy8fQ9AjhIdHa2SJUvq6NGjCggIMDscAACARw75EgB7YaUUgByJejwAAMCDkS8ByGoUpQAAAAAAAGB3FKUAAAAAAABgdzxTCgAAAAAAAHbHSikAAAAAAADYHUUpAAAAAAAA2B1FKQAAAAAAANgdRSkAAAAAAADYHUUpAAAAAAAA2B1FKQAAAAAAANgdRSkAAAAAAADYHUUpAAAAAAAA2B1FKQAAAAAAANjd/wMNSV90GHkkPAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nGenerating confusion matrix...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1000x800 with 2 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\nClassification Report:\n              precision    recall  f1-score   support\n\n   not bully       0.35      1.00      0.52      3068\n      sexual       0.00      0.00      0.00      1786\n      threat       0.00      0.00      0.00       339\n       troll       0.00      0.00      0.00      2093\n   religious       0.00      0.00      0.00      1515\n\n    accuracy                           0.35      8801\n   macro avg       0.07      0.20      0.10      8801\nweighted avg       0.12      0.35      0.18      8801\n\nচোরের মার বড় গলা\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 0 Axes>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1500x1000 with 3 Axes>",
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "U03DOREnBVNf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "UPf1djFoBVNf"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}